ID	YEAR	AUTHORS	TITLE	VENUE	SCOPE	TARGET	MOTIVATION	1) DATASET CURATION	TEST/TRAIN SPLIT	2) MODEL CHOICE	3) FEATURE SELECTION	TOPIC (if relevant)	4) EVALUATION	DISTRIBUTION SHIFTS?	ADVERSARIAL, REAL TIME, or OUT-OF-DISTRO TESTING?	BASELINES?	FOCUS SET ELIGIBLE?
001_f	2019	Abdullah-All-Tanvir; Ehesas Mia Mahir; Saima Akhter; Mohammad Rezwanul Huq	Detecting Fake News using Machine Learning and Deep Learning Algorithms	IEEE	claims (tweets), networks	(C.i) tweet semantics	rapidity of misinfo spread on social media; mentions U.S. presidential election in 2016	Chile earthquake dataset	60/20/20; 2-fold x validation	(2.ii) SVM, NB	(3.i) count, TF-IDF, n-gram representations of tweets	Chile earthquake in 2010	76% accuracy; compares to other classifiers, but not to different datasets	none described	none described	compared to SVM, RF, NB	TRUE
002_e	2010	Acemoglu, Daron and Oxdaglar, Asuman and ParandehGheibi, Ali	Spread of (mis)information in social networks	Games and Economic Behavior	networks	(N.ii) networks	does not present classifier, but models interactions between forceful agents and typical web users	n/a	n/a	n/a	(3.ii) 'each individual holds a belief represented by a scalar ... individuals meet pairwise and exchange information, which is modeled as both individuals adopting the average of their pre-meeting beliefs'	n/a	n/a	n/a	n/a		FALSE
003	2019	Addawood, Aseel; Badawy, Adam; Lerman, Kristina; Ferrara, Emilio	Linguistic Cues to Deception: Identifying Political Trolls on Social Media	AAAI	users	(A.i) language features of known troll accounts	Russian interference with 2016 U.S. presidential election	13 million election-related posts shared on Twitter in 2016 by over a million distinct users; includes 2,752 Russian troll accounts compiled and released by the U.S. Congress and all of the trolls’ discussions	10-fold x validation	(2.ii) RF, GBM	(3.i) morality, specificity, information complexity and quantity; (3.ii) user metadata	mixed topics; U.S. political news	for GBM, average F1-score 0.82 and average recall of 0.8	none described	none described	none described	TRUE
004	2012	Afroz, Sadia and Brennan, Michael and Greenstadt, Rachel.	Detecting Hoaxes, Frauds, and Deception in Writing Style Online	S & P	articles	(A.i) authorship detection from linguistic features; authors in training data have extremely idiosyncratic styles	deception will manifest in linguistic characteristics of text	extended brennan-greenstadt, brennan-greenstadt, hemingway-faulkner dataset from 2000-2005, Thomas-Amina Hoax corpus; Articles / essays. Brennan-Greenstadt adversarial dataset (participants asked to spend 30-60 mins writing in a style different from their own); extended B-G dataset developed by Turkers; Hemingway + Faulkner imitation contest. Idea is that it is possible distinguish *deliberately* deceptive writing from non-deceptive writing. 	authorship detection from linguistic features; Feature choice not great -- authors chosen have extremely idiosyncratic styles, don't map onto the styles of most misinformative communication	(2.ii) SVM classifier	(3.i) Lexical (character- and word-based; vocab and char choice. Total words; chars per word; frequency of large words; unique words); syntactic (POS tagging; sentence-level style; punctuation; function words [LIWC provided function words]); content-specific (words relevant to a specific subject / narrative); lexical and semantic methods		at least 80% accuracy on imitation and obfuscation tasks, but less than 50% on adversarial stylometry attacks; imitation attacks with 85% accuracy and obfuscation attacks with 89.5% accuracy on extended brennan-greenstadt; with lying detection, imitation attacks with 75.3% accuracy and obfuscation with 59.9% accuracy; 10-fold on Hemingway-Faulkner imitation corpus	digital forensics: detection of authorship from writing style. dataset and method unavailable. 'authors who are deceptive in their writing style are difficult to identify, however their deception itself is often detectable'	authors request that research assistants and Turkers manufacture writing in the style of other authors; not really -- just the three authors (Faulkner, Hemingway, McCarthy). and obfuscation detection only good for long-run corpora (e.g., won't be very effective for a single instance)	short-term deception detection is harder to detect; long-term detection more successful; deception possible to detect via second-order features (e.g., those particular to deliberate obfuscation)	FALSE
006	2020	Ahmad, I and Yousaf, M and Yousaf, S and Ahmad, Muhammad Ovais	Fake News Detection Using Machine Learning Ensemble Methods	Complexity	articles	(A.i) article sentiment; topic stance		ISOT; Kaggle datasets	veracity of news articles from voting ensemble methods	(2.ii) AdaBoost, XGBoost, LR, RF	(3.i) sentiment and stance detection		better than 0.9 on all datasets with different ensemble learners	social media detection; sharing news articles on Facebook; 2016 presidential elections; generalizable across different domains	domains are not generalizable; ensemble method helps w generalizability?	better performance than individual methods; no other explanation offered	FALSE
007_f	2019	Ajao, Oluwaseun and Bhowmik, Deepayan and Zargari, Shahrzad	Sentiment Aware Fake News Detection on Online Social Networks	IEEE	claims (tweets); images; networks	(C.i) tweet sentiment	social media detection	twitter dataset (PHEME)		(2.ii) LR, DT, RF, SVM	(3.i) sentiment; LIWC features	Charlie Hebdo, Sydney siege, Germanwings, Ferguson	0.86 on the PHEME dataset	none described	none described		FALSE
008	2018	Al Asaad, B and Erascu, M	A tool for fake news detection	20th international symposium on symbolic and numeric algorithms for scientific computing	articles	(A.i) title writing style		George McIntire dataset for content detection; Chakraborty dataset for title detection	social media; user enters link to article they want to verify	(2.ii) SVM and Naive Bayes	(3.i) NLP detection of clickbait-iness of title; bag of words, TF-IDF representation of title and contents		better than 0.8 for content and title classification; 0.94 for content classification	for real-time checking of articles at user-submitted links; is title clickbait or not	no	no	TRUE
011	2017	Amador, Julio; Oehmichen, Axel; Molina-Solana, Miguel	Characterizing Political Fake News in Twitter by its Meta-Data	arXiv:1712.05999 [cs, stat]	claims (tweets); networks	(U.i) user account metadata semantics	2016 U.S. presidential election	1.5M tweets collected on the day of the election of Donald Trump as 45th president of the United States of America	n/a	n/a; post hoc analysis only, no prediction	(3.ii) social graph patterns; (3.iii) account metadata	mixed	n/a	n/a	n/a		FALSE
012_f	2015	Antoniadis, Sotirios and Litou, Iouliana and Kalogeraki, Vana	A Model for Identifying Misinformation in Online Social Networks 	Springer	networks; claims (tweets); users	(N.i) networks; stylometry	rapid identification of misinformation spread on social media	80294 unique tweets and 59660 users	10-fold x validation	(2.ii) supervised ML: Bayes Network, KNN, J48, Adaptive Boosting, RF, Bootstrap Aggregating	(3.i) tweet sentiment, (3.ii) tweet metadata, including retweets and likes (3.iii) account metadata, including following/follower counts	Hurricane Sandy	RF achieves 0.792 average precision.	none described	claims real-time efficacy because models converge in several seconds; does not test on live content feeds		FALSE
013	2018	Aphiwongsophon, S and Chongstitvatana, P	Detecting fake news with machine learning method	 International conference on electrical engineering / electronics	claims (tweets)	(U.i) classification of user and (C.i) tweet metadata	detection of natural disaster-related misinformation on social media	948373 tweets posted between October-November 2017		(2.ii) Naive Bayes, SVM, (2.iii) Neural nets	(3.ii) tweet metadata, including retweets and likes (3.iii) account metadata, including following/follower counts and profile image	mixed Indonesian news topics	NB achieves accuracy 96.08%; NN and SVM achieve accuracy 99.90%	none described	none described		FALSE
014_f	2018	Asr, Fatemeh Torabi and Taboada, Maite	The Data Challenge in Misinformation Detection: Source Reputation vs. Content Veracity	Proceedings of the First Workshop on Fact Extraction and VERification (FEVER)	website; articles	(W.i) website reputation	generalization of whole-site labels to individual news articles	Buzzfeed News, Snopes	same as Rashkin's paper'	(2.iii) CNN, (2.ii) SVM	(3.iv) source; (3.i) style	mixed topic; U.S. news	SVM classifier achieved 0.96 and 0.75 F1 score on development and test sets	none described	tested on Rashkin et al. and Rubin et al. datasets; noted precipitous performance dropoff on Rubin dataset after training on Rashkin	none described	TRUE
015_e	2020	Atanasova, Pepa; Simonsen, Jakob Grue; Lioma, Christina; Augenstein, Isabelle	Generating Fact Checking Explanations	arXiv:2004.05773 [cs]	claims	[not strictly a classifier, though it does triage statements]											FALSE
016_f	2018	Baly, Ramy; Karadzhov, Georgi; Alexandrov, Dimitar; Glass, James; Nakov, Preslav	Predicting Factuality of Reporting and Bias of News Media Sources	EMNLP	websites	(W.i) factuality/bias of news site	whole news media' are understudied	1,066 websites for which both bias and factuality labels were explicitly provided, or could be easily inferred	5-fold x validation	(2.ii) SVM	(3.i) syntax, sentiment, topic, complexity; (3.ii) engagement; (3.iii) twitter user verified status; location; age; (3.iv) URL semantics, including use of https	U.S. political news	article features only yield accuracy 0.64 on factuality prediction and 41.74 on bias prediction	none described	none described	n/a	TRUE
017	2019	Bhutani, Bhavika and Rastogi, Neha and Sehgal, Priyanshu and Purwar, Archana	Fake News Detection Using Sentiment Analysis	IEEE	articles	(C.i) stylometry (sentiment analysis)		Politifact, Kaggle, and Emergent datasets; LIAR dataset	social media; incorporates sentiment; article representation	(2.ii) naive bayes	(3.i) Bi-grams, TF-IDF, Tri-grams, 		0.65 AUC for text+affiliation on LIAR; 0.185 accuracy with cosine similarity on LIAR; 0.80 on merged and george mcintire datasets with cosine similarity; no better than 0.30 on LIAR	social media?	better than similar methods without tf-idf and cosine similarity 	n/a	TRUE
018	2018	Borges, Luís; Martins, Bruno; Calado, Pável	Combining Similarity Features and Deep Representation Learning for Stance Detection in the Context of Checking Fake News	arXiv:1811.00706 [cs, stat]	articles; claims (first sentence of news article)	(A.ii) stance	combining similarity features w deep learning	SNLI and MultiNLI datasets of sentence pairs	90/10 train/test; 50 folds	(2.iii) bi-directional Recurrent Neural Networks (RNNs)	(3.i) embedding representations of headline, first two sentences, and entire news article	mixed topics	obtains 88% accuracy on SNLI dataset	n/a	n/a	n/a	FALSE
019	2017	Bourgonje, Peter; Moreno Schneider, Julian; Rehm, Georg	From Clickbait to Fake News Detection: An Approach based on Detecting the Stance of Headlines to Articles	Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism	articles	(A.i) n-gram matching on title and contents; stance detection	classifying relatedness of headline and body text	headlines and article contents from Fake News Challenge stance detection dataset; with unrelated, agree, disagree, discuss labels	50-fold x validation	(2.ii) LR	(3.i) relatedness of article body and headline	social media'; '2016 presidential election'; stance detection; detecting relatedness of article body and headline; headline clickbait detection toward a 'human in the loop' approach; 	weighted accuracy score of 89.59	detecting relevance of article contents and headlines, in order to flag 	n/a	n/a	FALSE
020	2020	Bozarth, Lia; Saraf, Aparajita; Budak, Ceren	Higher Ground? How Groundtruth Labeling Impacts Our Understanding of Fake News about the 2016 U.S. Presidential Nominees	Proceedings of the International AAAI Conference on Web and Social Media	news sites; claims (tweets); articles	(C.i) semantic content verification	choice of ground-truth affects determinations of misinfo (or not)	tweets about 2016 U.S. presidential candidates	undisclosed	topic modeling	(3.i) tweet contents	2016 U.S. presidential candidates	reports likelihood of labeling as misinfo w.r.t choice of ground truth	n/a	n/a	n/a	FALSE
021	2019	Brasoveanu, AM and Andonie R.	Semantic Fake News Detection: A Machine Learning Perspective	Advances in Computational Intelligence	articles	(C.i) semantic features; syntactic features; (A.i) sentiment		LIAR dataset	NLP / text analysis in conjunction with KG will work when its not possible to determine that source is verifiably good/bad				about 0.25 for most tasks, and at best about 0.644 for the best-performing deep learning model	early detection on news articles	including relational features like sentiment, named entities or facts extracted from both structured (e.g., Knowledge Graphs) and unstructured data (e.g., text), we generally obtain better scores on all classifiers	not really -- incorporation of more features increases performance differential compared to just checking on KGs	FALSE
022	2011	Budak, Ceren, Agrawal, Divyakant, and El Abbadi, Amr El	Limiting the Spread of Misinformation in Social Networks	Limiting the spread of misinformation in social networks	networks	(N.ii) networks	information 'inoculation'; treats misinfo as an epidemic; proposes optimization problem for identifying minimum set of good users to counteract bad	4 regional network graphs obtained from Facebook that exhibit properties such as power-law degree distribution, high clustering and positive assortativity	n/a	MCICM; (2.iv) greedy algo, degree centrality heuristic, early infectees and largest infectees heuristics	(3.ii) delay; propagation and network characteristics	n/a	MCICM saves more than 90% of users on 20% delay 	n/a	n/a		FALSE
023_f	2017	Buntain, Cody; Golbeck, Jennifer	Automatically Identifying Fake News in Popular Twitter Threads	2017 IEEE International Conference on Smart Cloud (SmartCloud)	networks; claims (tweets)	(A.ii) stance and disagreement between same-thread tweets	detection of rumoring/misinfo threads on web-scale datasets	CREDBANK and PHEME; Buzzfeed's Twitter fake news dataset	10-fold x validation	(2.ii) support vector machines, random forests, naive Bayes, stochastic gradient descent	(3.i) tweet sentiment and punctuation, (3.ii) tweet metadata, including retweets and likes (3.iii) account metadata, including following/follower counts	mixed; political news	CREDBANK-based models applied to the BuzzFeed achieved ROC-AUC of 73.80% and accuracy of 65.29%. 	none described	testing on different (well-known) datasets; none on novel or current data	https://github.com/cbuntain/CREDBANK-data	TRUE
024	2019	Burbach, Laura; Halbach, Patrick; Ziefle, Martina; Calero Valdez, André	Who Shares Fake News in Online Social Networks?	Proceedings of the 27th ACM Conference on User Modeling, Adaptation and Personalization - UMAP '19	networks; users	(U.i) (N.ii) networks	behavioral profile and model for misinfo spread on social networks	Undisclosed survey population for personality assessments	n/a	(2.iv) synthetic social network model	(3.i) personality characteristics of individual users	n/a	92% vs. 98% reach for different network densities	n/a	n/a	n/a	FALSE
026	2021	Carvalho, Paula; Caled, Danielle; Silva, Mário J.; Martins, Bruno; Carvalho, João Paulo; Carreira, Joaquim; Fonseca, João Pedro; Gomes, Teresa; Camacho, Pedro	Assessing News Credibility: Misinformation Content Indicators		articles (80 portuguese language)	(A.i) stylometry; article features (e.g. title)	content indicators for misinfo	80 news articles from Portuguese mainstream	n/a	manual annotation only	(3.i) title length, body length, expressivity, sentiment polarity	n/a	n/a	n/a	n/a	n/a	FALSE
027_f	2019	Castelo, Sonia et al. 	A topic-agnostic approach for identifying fake news pages	arXiv	websites	(C.i) linguistic features (topic-agnostic); (W.i) markup 	topics and discourse change constantly; topic-agnostic classifiers should be immune to these shifts	PoliticalNews dataset (web sites coming from Politifact, BuzzFeed, and OpenSources.co), plus sites from Alexa's top 500	five-fold x validation	(2.ii) SVM, KNN, RF	(3.iv) web markup features; (3.i) morphological features in site text	mixed topic; U.S. news	TAG model achieves accuracy 0.83 on PoliticalNews dataset	see next cell	authors train on one year (in the years 2013-18) and test on the others; implies that they train on future years and test on past years (leakage)	none described	FALSE
028	2011	Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara	Information credibility on twitter	WWW '11	networks; claims (tweets)	(C.i) stylometrics; (U.ii) user behavior		Tweets. Authors used twitter API to collect tweets related to 2500+ pre-determined topics (these were all related to `bursts' detected by Tweet Monitor); authors created keyword sets for each topic 	Turkers separated tweets by NEWS or CHAT on 383 topics; classifier was used to do automatic detection of NEWS or CHAT on full set of 2524 topics. 	(2.ii)  SVM, decision trees, decision rules, and Bayes networks	(3.i) message semantics (stylometry, length, sentiment analysis), (3.iii) user info (age, status count, friend count, url, descrip), topic (tweet count, tweet length, hashtag mention), and (3.ii) propagation patterns (number of initial tweets on topic, propagation max subtree, propagation max degree). 	mixed current news events topics	86% accuracy reported on automated credibility task; unclear if this was performed on a test set that included the training set -- might ask authors for splits; possible temporal leakage in classifier training step; 3-fold cross validation; > 0.909 classification performance for at least one feature set and classifier	none described	none described	significantly better than a random predictor'	FALSE
031	2015	Chen, Yimin; Conroy, Niall J.; Rubin, Victoria L.	Misleading Online Content: Recognizing Clickbait As "False News"	Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection	articles	(A.i); (N.i) stylometrics; source; network		[this is a five-page research proposal]; 'our review does not depict a concrete implementation which merges methods to a prototype application'	clickbait-y headlines' as a proxy for misinformation	SVMs, NB, frequency analysis, PCFG, neural net analysis, image detection, image caption analysis, web traffic analysis, and web metadata analysis	approaches to clickbait identification include: lexics/semantics, syntax/pragmatics, images, and news reader behavior		none	unspecified	unspecified	unspecified	FALSE
032_f	2020	Chen, Zhouhan; Freire, Juliana	Proactive Discovery of Fake News Domains from Real-Time Social Media Feeds	Companion Proceedings of the Web Conference 2020	website	(N.ii) user sharing patterns; (W.iv) infrastructure features, including presence of SVGs and underscores in markup	the problem of discovering new sources of fake news has been largely unexplored'	PoliticalFakeNews dataset for training; 220,909 tweets collected from the Twitter Streaming API in the 24 hours beginning October 29, 2019 for testing	5-fold x validation	(2.ii) SVM	(3.iii) uses twitter feeds to uncover user co-sharing structures to discover political news websites; uses a topic-agnostic classifier to score and rank newly discovered domains	2020 process to 'impeach donald trump'	70% of domains in training predicted to be suspicious; by comparison, 76% of domains that have been manually fact-checked have ratings below 'mostly factual'	none described	user input is needed to further classify the sites'		TRUE
033	2014	Cheng, Justin and Adamic, Lada and Dow, P. Alex and Kleinberg, Jon Michael and Leskovec, Jure	Can cascades be predicted?	WWW Proceedings	claims (facebook)	(N.ii) propagation/virality	early prediction of information cascades/virality on facebook	facebook posts	10-fold x validation	(2.ii) RF	(3.iii) time of posting; (3.i) post contents; (3.ii) poster account semantics	mixed topic	accuracy 0.497	none described	real-time testing emulated with planned delays	better than random guessing	FALSE
034_r	2015	Ciampaglia, Giovanni Luca; Shiralkar, Prashant; Rocha, Luis M.; Bollen, Johan; Menczer, Filippo; Flammini, Alessandro	Computational Fact Checking from Knowledge Networks	PLOS ONE	claim	(C.i) semantic distance from embeddings	manual checking is too slow!	Knowledge graph extracted from subject-predicate-object statements (those formulated from Wikipedia infoboxes). Nodes are entities, edges are predicates. Absence of edges or short paths implies falsehood. Path length should account for information density / specificity / degree of connectivity. Authors built Wikipedia Knowledge Graph (WKG), with 3 million entity nodes linked by 23 million edges.	not specified; re-check t-t split and possible temporal leakage ; impossible to implement as a real-time tool; 10-fold cross-validation	(2.ii) RF	(3.ii) path length; existence / non-existence of path length; (3.i) text entailment [for KG extracted from free text]	topics include films, Congress, US states and their capitals, world countries and capitals	true statements are assigned higher truth values than false ones with probability 95%, 98%, 61%, and 95%, respectively.	KG not robust to distro shifts			FALSE
036	2019	Cui, L and Wang, S and Lee, D	Same: sentiment-aware multi-modal embedding for detecting fake news	Proceedings of the 2019 IEEE/ACM international conference on advances in social networks analysis and mining	articles; image; users	(A.i) stylometrics; image data		politifact and gossipcop	user sentiment as a determiner of news veracity	EANN (adversarial learning)	yes 		between 65 and 78% on PolitiFact; between 77 and 82 on GossipCop	fake news detection on social media (method incorporates user responses to posts as indicators of 'sentiment')	comparison to SOTA (including CSI, by Ruchansky)	better than SOTA	FALSE
037	2020	Darwish et al. 	Unsupervised user stance detection on twitter	AAAI	users	(A.ii) topic and stance of 'prolific users' ' tweets; (N.i) propagation and popularity of rumoring stances/topics	stance detection 'has broad applications in studying public opinion, political campaigning, and marketing'	for training, three labeled datasets, relating to 1) Brett Kavanaugh confirmation; 2) Trump and 2018 midterm elections, and 3) Erdogan dataset. new/test datasets pertain to six other rumoring events	none described	(2.iv) graph clustering algos, including DBScan and MeanShift	dimensionality reduction of user features 	mixed U.S. and int'l news rumors on topics including immigration and gun control, Israel, and benefits/dangers of vaccines	average cluster purity was 98.0% with an average recall of 86.5%	none described	none described	none described	FALSE
039	2020	Debnath, Amar; Rahman, Redoan; Mofijul Islam, Md.; Abdur Razzaque, Md.	A Hierarchical Learning Model for Claim Validation (2020)	Proceedings of International Joint Conference on Computational Intelligence	claim	(C.i) undisclosed language cues	mentions trump; aims to distinguish deceptive text from truthful text using language cues	LIAR for training AND evaluation; Politifact; weird padding of LIAR inputs to 100 words; author 		padding gets weirder when you consider that they're using sent2vec; unclear if the CNN was used for final evaluation	(3.iii) author profile; (3.i) 'text features'; 'linguistic cues' from cnn and transfer learning	political news; election 2016 statements	authors state that knowledge of author profile details improves accuracy to 28.75%; accuracy on all tasks below 30%, precision and recall also around 28%	no mention; static dataset used for training and validation	all datasets are within distribution and within domain (2016 election news)	though authors cite human evaluators' baseline as ranging from 50% to 63%, they compare their own method performance to the LIAR baseline, which is 27%	FALSE
040	2018	Del Vicario, M and Quattrociocchi, W and Scala, A and Zollo, F	Polarization and fake news : early warnings of potential misinformation targets	arXiv	claims (facebook); articles	(U.ii) individual user behaviors, (N.ii) user-user interactions	early warning re misinfo online; Trump election; Brexit; increased polarization online	Italian Facebook dataset with more than 300K news from official newspapers and 50K posts from websites disseminating either fake or unsubstantiated information	60/40 train/test	(2.ii) Linear Regression, Logistic Regression, Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and (2.iii) Neural Network Models (NN)	(3.i) post sentiment; (3.ii) comment sentiment and 'captivation' (engagement)	mixed news; Italian news websites	91% accuracy (0.94 AUC)	none described	none described		TRUE
041	2018	Della Vedova, Marco; Tacchini, Eugenio; Moret, Stefano; Ballarin, Gabriele; Di Pierro, Massimo; de Alfaro, Luca	Automatic Online Fake News Detection Combining Content and Social Signals	IEEE	claims; user behaviors	(U.ii), (N.ii) network and 'social' signals; (C.i) posting contents	2016 U.S. presidential election; 2013 Boston Marathon bombing; need for fast fact verification in light of high volume of information online	FakeNewsNet (PolitiFact and Buzzfeed)	shuffle split cross validation with 50 iterations and a training set size equals to 10% of the entire FacebookData dataset	(2.ii) Logistic regression on social network features	(3.i) post contents, including title and text preview of linked content; (3.ii) counts of likes and other social interactions 	political news	90.3% accuracy	none described	none described		TRUE
042	2018	Dey, Amitabha and Rafi, Rafsan Zani and Parash, Shahriar Hasan and Arko, Sauvik Kundu	Fake news pattern recognition using linguistic analysis	International conference on informatics, electronics and vision; international conference on imaging, vision and pattern recognition	articles; claims	(A.i) stylometry	2016 U.S. presidential election; short paper	dataset comprising 200 tweets on “Hilary Clinton”	not disclosed	(2.ii) KNN	(3.i) article sentiment magnitude vs. length of article, the sentiment of credible and malicious article and the relationship between average length of each word and the number of words in the article	Hillary Clinton	66.66% accuracy 	none described	none described	none described	FALSE
043	2019	Dhamani, Numa; Azunre, Paul; Gleason, Jeffrey L.; Corcoran, Craig; Honke, Garrett; Kramer, Steve; Morgan, Jonathon	Using Deep Networks and Transfer Learning to Address Disinformation	arXiv:1905.10412 [cs]	articles	(A.i) stylometrics; semantics		Enron emails; NASA JPL emails; movie review database; spam fraud corpus		CNN for character-level stuff, LSTM on the second layer	topic classification, sentiment analysis		96.14% on spam email detection (classification of 'friend' or 'foe'), 99.5% on movie review classification (on-topic or off-topic), 88.10% on political sentiment classification ('pro,' 'anti,' or 'neutral,' with 100% accuracy on negative sentiment posts) 	spam email detection, review bombing, political sentiment, conversation clustering	efficacy of transfer learning demonstrates that methods are suitable to 'the rapidly changing social media ecosystem'	the flexibility of this framework to create a compact rep of natural language across a variety of comm channels by analyzing char-to-char contingencies makes it a powerful tool with broad potential to affect the quality and integrity of online discourse'	FALSE
044	2018	Dong, M and Yao, L and Wang, X and Benatallah, B and Sheng, QZ and Huang, H	Dual: a deep unified attention model with latent relation representations for fake news detection	International conference on web information systems engineering	articles	(C.i) context (comments) and stylometry		LIAR; Buzzfeed News. text posts converted to word embeddings. 		attention-based bi-directional Gated Recurrent Units (GRU) to extract features from news content and a deep model to extract hidden representations of the side information	speakers’ profiles and reviewers’ feedback		LIAR: 0.8283 Acc, 0.7621 Prec, 0.8112 Recall, 0.7859 F1. Buzzfeed News: 0.8384 Acc, 0.9167 Prec, 0.7857 Recall, 0.8462 F1.	n/a	n/a	incomplete repo available at: https://github.com/dongmanqing/A-Deep-Unified-Attention-Model-with-LatentRelation-Representations	FALSE
045	2019	Dong, Xishuang; Victor, Uboho; Chowdhury, Shanta; Qian, Lijun	Deep Two-path Semi-supervised Learning for Fake News Detection	arXiv:1906.05659 [cs]	claims (tweets)	(C.i) stylometrics	2016 U.S. presidential election; volume of social media misinformation	PHEME (tweets)	leave-one-event-out (LOEO) cross-validation	(2.iii) CNNs	(3.i) post contents. Extraction from text features using TF-IDF	Germanwings-crash; (GC), Charlie Hebdo (CH), Sydney siege (SS), Ferguson (FE), and Ottawa shooting (OS).	83.33% Prec., 33.33% Recall, 47.62% Fscore on GC with 5% labeled data	none described	none described		TRUE
047	2017	Farajtabar, M and Yang, J and Ye, X and Xu, H and Trivedi, R and Khalil, E et al	Fake news mitigation via point process based intervention	arXiv	users; networks	(N.ii) exposure over time to real and fake news events	intervention strategy formulated as a graph problem	synthetic social graph, based on twitter social graph topology	n/a	Multivariate Hawkes processes with exogenous intervention	(3.ii) networked interactions with real/fake events	n/a	30-40% reduction in exposure versus a random baseline	n/a	yes, real-time experiment was conducted		FALSE
049_e	2020	Freelon, Deen; Bossetta, Michael; Wells, Chris; Lukito, Josephine; Xia, Yiping; Adams, Kirsten	Black Trolls Matter: Racial and Ideological Asymmetries in Social Media Disinformation	Social Science Computer Review	users			IRA (Russian troll farm) tweets, 5.2M tweet dataset; 									FALSE
050	2015	Galitsky, B	Detecting rumor and disinformation by web mining	AAAI Spring symposium series	claims; sources	(W.i) identifies source text from given excerpt	lots of misinformation consists of incremental edits to similar blocks of text (inversion)	1000(?) customer reviews mined from Yahoo, Amazon, other undisclosed sources. authors admit that disinformation, rumors, and opinions are not necessarily equivalent	undisclosed	parse thickets and 'discourse trees'	(3.i) bagsofwords representations of seed sentence and retrieved web sources; inference of correctness from authority of source of closest representation of sentence on the web	product reviews	source page identification up to 80%; actual accuracy for verifying misinfo is about 70%. actual disinformation detection not successful; instead, proxy detection ('source material, entity substitution, sentiment detection') much more successful	no mention	no; only product reviews	none reported	FALSE
052	2020	George, Joma; Skariah, Shintu Mariam; Aleena Xavier, T	Role of Contextual Features in Fake News Detection: A Review	2020 International Conference on Innovative Trends in Information Technology (ICITIIT)	claims (tweets)	(C.i) stylometrics	2016 U.S. presidential election; volume of social media misinformation	merged dataset (combining Kaggle, Politifact and Emergent datasets), George McIntire dataset, and LIAR dataset	unspecified	(2.ii) Naive Bayes, KNN, SVM, Decision tree, (2.iii) Hybrid CNN, CMS	(3.i) post contents. (3.iii) 'contextual features', including 'speaker, speaker history, speaker job title, party, etc.' Extraction process unspecified.	political news	Accuracies attained by SVM (86%), Logistic regression (84%), Decision trees (77%), Random Forest (85%), XG-Boost (84%), LSTM-HAN (86%)	none described	none described		FALSE
053_e	2022	Glockner et al 	absence of counter-evidence renders NLP fact-checking unrealistic		claims	https://drive.google.com/drive/u/2/folders/1_vpD0tXgCIxTMU8npSFgj2KxCfHXKAAB	authors cite COVID-19, Pizzagate, U.S. presidential election			authors find that manual fact-check are rigorous and hard to complete in the absence of counterclaims; authors review existing fact-checked data sets and methods with NLP components	[note: not a detection method; authors evaluate existing NLP-driven methods and find that overreliance of leaked counter evidence renders them incapable of evaluating real-world misinfo]		leaked' counterevidence informs classification decisions during train and test; 			comparisons made to human fact-checkers 	FALSE
055	2017	Granik, M and Mesyura, V	Fake news detection using naive Bayes classifier	IEEE First Ukraine Conference on Electrical and Computer Engineering	claims (facebook posts)	(C.i) stylometrics; syntax	spam and misinfo share common linguistic features	Buzzfeed News (Facebook posts)	unspecified	(2.ii) Naive Bayes	(3.i) post contents	political news	The precision for the given classifier equals to 0.71; recall, on the other hand equals to 0.13	none described	none described		FALSE
057	2018	Guo, H and Cao, J and Zhang, Y and Guo, J and Li, J	Rumor detection with hierarchical social attention network. 	Proceedings of the 27th ACM international conference on information and knowledge	networks (LSTM)	(U.i) account metadata; (U.ii) account social behaviors; (C.i) post contents; (N.i) post propagation	volume of information on microblogs	Weibo, Twitter	80/20 train/test	(2.iii) a novel hierarchical neural network combined with social information (HSA-BLSTM)	(3.i) post contents, including punctuation. (3.ii) network features, including reposts and shares. (3.iii) user features, including verified follower count, number of friends	mixed news; Chinese news sites	HPA-BLSTM achieves 0.936 acc., overall and 0.968 precision, 0.901 recall, 0.933 F1 for rumors; 0.910 precision., 0.970 recall and 0.939 F1 for non-rumors.	none described	none described		TRUE
058	2014	Gupta, A and Kumaraguru, P and Castillo, C and Meier, P	Tweetcred: Real-time credibility assessment of content on twitter. 	International conference on social informatics	claims (tweets); users	(U.i) tweet credibility	real-time detection during natural disasters and mass casualty events (Hurricane Sandy, 2013 Boston Marathon bombing)	authors construct Twitter dataset from Twitter API, for a set of events of interest, including Hurricane Sandy, 2013 Boston Marathon bombing. Authors obtained manual labels for around 500 tweets selected uniformly at random from each event.	unspecified	(2.ii) SVM	(3.i) post contents, including presence of swear words and emotional valence; (3.ii) networked behaviors, including number of likes and reshares; (3.iii) author reputation, including follower count and account age	news by topic, including natural disasters and mass casualty events	80% of the credibility scores are computed and displayed within 6 seconds; 63% of users either agreed with automatically-generated scores or disagreed by 1 or 2 points (on a scale from 1 to 7).	none described	claims real-time efficacy because models converge in several seconds; does not test on live content feeds		FALSE
059	2017	H. Ahmed, I. Traoré, Sherif Saad	Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques	International Conference on Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments	articles	(C.i) semantic contents	speed and volume of social media misinfo	Real news from Reuters; fake news from Politifact	5-fold x validation	Authors compare K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Logistic Regression (LR), Linear Support Vector Machine (LSVM), Decision tree (DT) and Stochastic Gradient Descent (SGD); find Linear Support Vector Machine (LSVM) most performant	TF-IDF for feature extraction; 		Author evaluate 6 different models x 2 different feature extraction techniques x for n-grams ranging from 1 to 4. Highest accuracy achieved on unigram features and Linear SVM classifier. The highest accuracy score is 92%.	n/a	Authors test also on Adali and Horne (Buzzfeed and other news websites) and Burfoot and Baldwin satire datasets; no real-time testing		FALSE
060	2018	H. Ahmed, I. Traoré, Sherif Saad	Detecting opinion spams and fake news using text classification	Security and Privacy	claims (reviews)	(C.i) post semantics and style	2016 U.S. presidential election; fake reviews and fake news share linguistic similarities	hotel review dataset; PolitiFact news dataset. TF or TF-IDF to extract features from word embeddings	80/20 train/test; 5-fold x validation	(2.ii) SGD, SVM, LSVM, LR, KNN, and DT	(3.i) post contents, review and n-gram length; (3.iii) reviewed business name (hotel) 	hotel reviews; political news	90% accuracy on bigrams and 10000-length features	none described	none described		TRUE
063_f	2020	Hamdi, Tarek; Slimi, Hamda; Bounhas, Ibrahim; Slimani, Yahya	A Hybrid Approach for Fake News Detection in Twitter Based on User Features and Graph Embedding	Distributed Computing and Internet Technology	users; user behaviors	(U.i) user account semantics; (U.ii) sharing patterns	combining user and graph features to infer fake news posts	CREDBANK	authors test a variety of splits, from 20/80 train/test to 80/20 train/test	(2.ii) tested SVM, DT, RF, KNN, BN, LR	(3.iii) statuses posted, account age, verification status; (3.ii) followership, social graph representations among users. node2vec representations of these features	n/a	LR achieves AUC_ROC 0.87 on user-based features only and AUC_ROC 0.996 on node-based features only	none described	none described		FALSE
064_f	2018	Hamid Karimi, Proteek Chandan Roy, Sari Saba-Sadiya, and Jiliang Tang	Multi-Source Multi-Class Fake News Detection	Proceedings of the 27th International Conference on Computational Linguistics	sources; articles	multimodal	since we have not gained enough insights into the nature of fake news, hand-crafted features based on the news content are generally not sufficient'; degrees of fakeness more informative than true/false labels	LIAR dataset	80/10/10 train/tune/test	(2.iii) CNN	(3.i) word embeddings of published statements; verdict reports generated by politifact labelers; (3.iii) user metadata, including job and political affiliation; count of past true/false statements. 	U.S. political news	accuracy 38.81 using all feature classes	none described	none described	comparison to SVM, RF, NN, random, majority class	TRUE
065	2012	Harris, Christopher.	Detecting deceptive opinion spam using human computation.	Proceedings of the Workshops at AAAI on Artificial Intelligence	posts (reviews)	(C.i) post semantics and style	detection of opinion spam (fake reviews)	real reviews from TripAdvisor	unspecified	(2.ii) SVM	(3.i) post contents, including complexity, word count, lexical diversity, presence of brand names	product and vacation reviews	76% accuracy on well-rated reviews; 78% precision and 76% recall on truthful reviews; 77% precision and 75% recall on deceptive reviews	none described	none described		FALSE
066	2017	Hassan, Naeemul; Arslan, Fatma; Li, Chengkai; Tremayne, Mark	Toward Automated Fact-Checking: Detecting Check-worthy Factual Claims by ClaimBuster	Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17	claim	(C.i) semantic verification 	mentions 2016 u.s. election; mentions that manual fact-checking is too slow; presents ClaimBuster (nlp and supervised learning); resource scarcity for journalists	claims made by presidential candidates during past presidential debates [classified statements into non-factual, unimportant factual, important factual]; ground truth fact database was labeled by study participants		doesn't actually provide misinfo/disinfo classification, only flags things for further verification	(3.i) sentiment, length, word, part-of-speech tagging, entity type. 6615 features in total; trained a random forest classifier and used GINI index t o measure importance of features in decision tree construction; after selection of feature types, authors performed 3-class classification using multinomial naive bayes, svm, and random forest classifiers. 	election misinformation	4-fold x-validation; up to 0.96 on certain combos of feature sets for binary classification of NFS and CFS		ClaimBuster’s scorer was tested in real-time during the live coverage of all primary election and general election debates for the 2016 election.Closed captions of the debates on live TV broadcasts, captured bya decoding device, were fed to ClaimBuster, which immediately scored each sentence spoken by the candidates and posted top-scored claims to the project’s website (idir.uta.edu/claimbuster) and Twitter account (@ClaimBusterTM). Post-hoc analysis of the claims checked by professional fact-checkers at CNN, PolitiFact.com and FactCheck.org reveals a highly positive correlation between ClaimBuster and journalism organizations in deciding which claims to check.		FALSE
067	2014	Hassan, Naeemul; Sultana, Afroza; Wu, You; Zhang, Gensheng; Li, Chengkai; Yang, Jun; Yu, Cong	Data in, fact out: automated monitoring of facts by FactWatcher	Proceedings of the VLDB Endowment	claim	(C.i) (C.iv) content; check-worthiness of factual claims	mentions resource scarcity for journalists	NBA dataset; weather dataset (all stats-heavy, fairly structurally rigid)	unreported	supervised; training on box scores and weather reports	(3.i) for NBA dataset, user can include points, rebounds, and assists in 'interestingness' score; also 'interestingness; popularity; and recentness'; authors claim that longer elapsed time since occurrence of a similar fact implies higher interestingness; time-of-publication	NBA score reports and weather data	evaluation on the same	constrained in-domain dataset; out of domain data not discussed			FALSE
068	2018	Helmstetter, Stefan et al. 	Weakly Supervised Learning for Fake News Detection on Twitter	2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	posts (tweets)	(U.i) tweet credibility from user-level credibility scores	difficult to obtain large-scale manually-annotated tweet dataset; source-level labeling is easier	authors use Twitter API to collect tweets from credible and non-credible sources, as determined by the DMOZ catalog and opensources, Mashable, and Snopes	unspecified	(2.ii) SVM, RF, DT, NB, NN	(3.i) text and topic; (3.ii) user features; (3.iii) tweet interaction features	mixed; political news and satire	F1 score up to 0.90	none described	none described		FALSE
069	1995	Hernon, Peter.	Disinformation and misinformation through the internet: Findings of an exploratory study.	Government Information quarterly	articles; claims			OLD	OLD	OLD	OLD		OLD	OLD	OLD	OLD	FALSE
070	2019	Heydari, Aarash; Zhang, Janny; Appel, Shaan; Wu, Xinyi; Ranade, Professor Gireeja	YouTube Chatter: Understanding Online Comments Discourse on Misinformative and Political YouTube Videos	arXiv	posts (comments and videos)	(A.i) predicting bias of a video from linguistic characteristics of comments on videos produced by accounts with known biases	(U.i) channel-level credibility 	MediaBiasFactCheck for channel labels	unspecified	(2.ii) Decision Tree, Random Forest, Linear SVM, and SVM with RBF kernel	(3.i) text and topic; (3.ii) account reputation; (3.iii) total comment count	mixed; political and science news	DT accuracy 80.2%; SVM accuracy 79.0%	none described	none described		FALSE
071	2017	Horne, Benjamin D.; Adali, Sibel	This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News	AAAI CWSM'17	articles	(A.i) LIWC, sentiment analysis, frequency analysis; news headlines in real, fake, and satire articles; headline veracity as proxy for whole article veracity		Buzzfeed election data (2016); one novel dataset constructed by authors, from political news sites, contains real (Business Insider's most trusted list)/fake (Zimdars)/satire (unspecified) pieces; real and satire articles from Burfoot and Baldwin	5-fold x-validation	(2.ii) linear kernel SVMs on small feature sets; hodge podge of features thrown into SVM classifier	stylistic (python nltk, pos tagging; stop words, punctuation, quotes, negations, informal swear words, interrogatives; LIWC); complexity (sentence- and word-level; gunning fog; smog grade; flesh-kincaid grade level indices; type-token ratio for lexical diversity; fluency, how common or specialized document vocab is); psychological (LIWC; sentiment analysis; bag-of-words sentiment; senti-strength for capturing intensity of pos/neg emotion); 		91% x-validation acc for separating satire from real; 67% for classifying fake and satire article bodies; 75% x-validation accuracy separating satire titles from real titles, but only 55% separating satire titles from fake titles 	assumption is that readers will see news article title and make a snap judgement about readability / factuality of article text from title	title detection a good sim of users with limited attention spans /who are not likely to read much further	not really -- just that it's a bit above baseline, and that's fine enough	FALSE
072	2018	Hosseinimotlagh, Seyedmehdi; Papalexakis, Evangelos E	Unsupervised Content-Based Identification of Fake News Articles with Tensor Decomposition Ensembles		articles	stylometrics		all articles in dataset are from bullshit sites!	detection of 'types' of disinfo: conspiracy, 'state', satire, junk sci, biased, hate	considers 'spatial relation' of words in addition to existence and frequency	yes -- content analysis		better than 0.8 at classifying misinfo into misinfo categories	early identification of fake news, before they find their way in online fact-checking repositories, potentially using solely their content, is imperative'	not really -- claim that their method performs all existing methods on classification tasks	nope	FALSE
073_f	2020	Hounsel, Austin; Holland, Jordan; Feamster, Nick; Kaiser, Ben; Borgolte, Kevin; Mayer, Jonathan	Identifying Disinformation Websites Using Infrastructure Features	USENIX Security	websites	(W.iv) hosting infrastructure	early detection of misinfo news sites from infrastructure features (topic-agnostic detection)	551 disinformation sites, 553 news sites, and 555 non-news sites integrated from Snopes, Factcheck.org, CBS, Wikipedia, Buzzfeed, PolitiFact	five-fold x validation	(2.ii) RF	(3.iv) website’s domain, certificate, and hosting characteristics	mixed topic; U.S. news	0.98, 0.95, and 0.98 ROC AUC resp. for authentic news websites, disinformation websites, and other websites; much worse in real time	see next cell	real-time classification performed on CertStream, Reddit API, Twitter API, and DomainTools sites	none described	TRUE
074	2021	Jabiyev, Bahruz; Onarlioglu, Kaan; Pehlivanoglu, Sinan; Kirda, Engin	FADE: Detecting Fake News Articles on the Web		articles	(U.i) source reputation ('reputation graph')		4750 fake and 4750 real news articles	news articles	(2.iv) 'reputation graph'	not really -- just source reputability checks ('automating the process that web users undergo to determine text veracity')		87% on a test set of 500 fake and 500 real news articles; 85% on browser extension implementation, wherein users query specific news articles and 'view detection reports'	browser extension: user querying veracity of article during web search: 'In essence, we automate the actiosn Internet users need to perform to validate a news article, and provide machine learning support for their decision-making process'	choice of search engine and underlying library will have outsize impact on classifier performance	real time detection' conducted via daily scrapes of politifact and factcheck.org from the previous day; 85% accuracy on this task. authors admit that accuracy could be improved by expanding trusted sources list (particularly to include local news outlets)	FALSE
075	2019	Jadhav, SS and Thepade, SD	Fake news identification and classification using DSSM and improved recurrent neural network classifier (2019)	Applied artificial intelligence	claims (LIAR dataset)	(C.i), (A.i) veracity of claims using linguistic cues	lack of world knowledge for emergent news means that checking method needs to rely on linguistic cues instead	LIAR dataset (twitter data)	authors try 50/50, 80/20, and 75/25	(2.iii) unsupervised; RNN and DSSM (for capturing semantic subleties in text)	unspecified; opaque (unsupervised method)	would be influenced by choice of query	not distinct from test/train; accuracy is up to 99%	undisclosed (and now possibly moot because of the API shutdown)	not discussed		FALSE
076	2016	Jain, S and Sharma, V and Kaushal, R	Towards automated real-time detection of misinformation on twitter	International conference on advances in computing	posts (tweets)	(U.i) source reputation (news site or personal account); (N.i) clusters of tweets discussing trending topics; (C.i) tweet sentiment and tone	real-time detection of misinformation on Twitter	Twitter API for topic-specific tweets	unspecified	(2.iv) Clustering on social graph 	(3.i) text and topic; (3.ii) account reputation	mixed; political news in India	77% accuracy on a Digital India Rumor topic	none described	none described		FALSE
077	2019	Janicka, Maria; Pszona, Maria; Wawer, Aleksander	Cross-Domain Failures of Fake News Detection	Computación y Sistemas	articles	(A.i) stylometry	cross-domain testing	x									FALSE
078	2018	Jiang, Shan; Wilson, Christo	Linguistic Signals under Misinformation and Fact-Checking: Evidence from User Comments on Social Media	Proceedings of the ACM on Human-Computer Interaction	post (Facebook and Twitter posts; Youtube comments)	(U.ii) user comments on social media posts; (C.i) comment sentiment	inferring news article credibility from commenter sentiment	5,303 social media posts with 2,614,374 user comments from Facebook, Twitter, and YouTube, and associate these posts to fact-check articles from Snopes and PolitiFact for veracity rulings	unspecified	Linguistic features extracted using custom ComLex lexicon instead of LIWC and Empath; (2.ii) LR and SVM; (2.iii) NN	(3.i) comment sentiment; (3.ii) source reputation	political news	LRL of 0.760 using ComLex	none described	none described		FALSE
079	2013	Jin, Fang; Dougherty, Edward; Saraf, Parang; Cao, Yang; Ramakrishnan, Naren	Epidemiological modeling of news and rumors on Twitter	Proceedings of the 7th Workshop on Social Network Mining and Analysis	posts (tweets)	(N.i) content-agnostic propagation patterns induced by rumoring topics; SEIZ (susceptible, exposed, infected, skeptic) epi model in particular	social movement organizing; Arab Spring	Twitter API for topic-specific tweets	unspecified	(2.iv) epi. diffusion model based on SEIZ epi model	(3.ii) account followership and response ratios	eight representative stories (four true events and four rumors) across a range of topics (politics, terrorism, entertainment, and crime) and over several geographic regions (USA, Mexico, Venezuela, Cuba, Vatican).	Error of 0.029 for Obama-related rumor model using SEIZ	none described	none described		FALSE
080	2017	Jin, Z and Cao, J and Guo, H and Zhang, Y and Wang, Y and Luo, J	Detection and analysis of 2016 US Presidential election related rumors on twitter	International conference on social computing, behavioral-cultural modeling and prediction and behavior representation in modeling and simulation	posts (tweets)	(A.ii) tweet topic	2016 U.S. presidential election	8M tweets produced by followers of Trump and Clinton; checked rumors verified by Snopes	unspecified	authors use feature extraction models as 'matching' mechanism for tweets on both candidates	TF-IDF, BM25, Word2Vec and Doc2Vec represent texts as numeric vectors; 	political campaign news (2016 U.S. presidential election)	odd result: '1.2% tweets are rumor tweets from Clinton’s followers, which is about 4% more than that of Trump’s followers';  rumor detection precision of 94.7%	none described	none described		FALSE
081	2016	Jin, Z and Cao, J and Zhang, Y and Luo, J	News verification by exploiting conflicting social viewpoints in microblogs	AAAI	posts (tweets)	(C.i) stance detection; (N.ii) tweet networks	volume of information on microblogs	authors select tweets with 'conflicting relations': these pairs are linked nodes in a social graph. From Sina Weibo, authors extract 73 fake news and 73 real news composed of 49,713 tweets, involving 42,310 distinct users	unspecified	(2.iv) K-means clustering	(3.i) stance; (3.ii) tweet-to-tweet relationships	mixed; political news in China	news classification accuracy 84%	none described	none described		FALSE
082	2017	Jin, Z and Cao, J and Zhang, Y and Zhou, J and Tian, Q	Novel visual and statistical image features for microblogs news verification	IEEE Transactions on multimedia	posts (tweets); users	verification of factuality from image classification	infrastructure; stylometry; user	50287 tweets and 25,953 images in fake and real news events on Sina Weibo are collected.	unspecified	(2.i) cosine similarity for distance calculations on image vectors; (2.ii) SVM, LR, RF	GIST for image feature extraction; (3.i) text and topic; (3.ii) user features; (3.iii) tweet interaction features	mixed; political news in China	Random Forest generates the best accuracy of 83.6%; improvement of 7% over feature sets that don't include image data	none described	none described		FALSE
083	2014	Jin, Zhiwei and Cao, Juan and Jiang, Yu-Gang and Zhang, Y	News credibility evaluation on microblog with a hierarchical propagation model	ICDM	posts (tweets); users; events	(U.ii) post veracity from account credibility; (N.i) propagation patterns on social graphs of posts and users	detection of misinformation on microblogging sites	Sina Weibo posts; SW-2013 and SW-MH370. SW-2013 is topic agnostic: contains 18 fake news and 171 true news stories, represented by 79296 Microblog messages. SWMH370 comprises news related to the same topic “Flight MH370 Lost Contact”. It contains 32 fake news and 135 true news stories, represented by 32526 Microblog messages. 	unspecified; 4-fold x validation	(2.ii) SVM; NewsCP (gradient descent)	(3.i) text, hashtags, URLs; (3.ii) reshares, comments, likes; (3.iii) user features (followership)	one dataset is topic agnostic; the other contains posts discussing the disappearance of MH370	NewsCP achieves 89% accuracy, 45% precision, 72% recall, and 55% Fscore on a topic-agnostic dataset and 85% accuracy, 66% precision, 78% recall, and 71% Fscore on a topic-specific dataset	none described	none described		FALSE
086	2021	Juneja, Prerna; Mitra, Tanushree	Auditing E-Commerce Platforms for Algorithmically Curated Vaccine Misinformation	Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems	product descriptions on e-commerce sites	(U.i) product descriptions, including text and images	amplification of vaccine misinformation on e-commerce sites; misinformation classifier isn't final goal of the work, but authors perform some classification of large dataset of SERPs 	Unpersonalized audit on a curated list of 48 search queries belonging to 10 most searched vaccine-related topics	n/a	unspecified	(3.i) text sentiment, product image, book's preview	products possibly related to vaccine (misinformation), including medical equipment, books, and dietary supplements	n/a	n/a	n/a		FALSE
087	2019	K, Anoop; P, Deepak; L, Lajish V.	Emotion Cognizance Improves Fake News Identification	arXiv:1906.10365 [cs]	articles	(A.i) semantics; stylometry	contribution of affective character of writing to misinfo detectoin	Health and Well Being dataset	10 splits	(2.ii) NB, SVM, KNN, RF, DT, AB, (2.iii) CNN, LSTM	(3.i) emotional intensity lexicons	health-related content	Adaboost achieves accuracy 96.5%			incorporation of sentiment features improves detection accuracy	FALSE
088	2020	Kaliyar, Rohit Kumar; Goswami, Anurag; Narang, Pratik; Sinha, Soumendu	FNDNet- A Deep Convolutional Neural Network for Fake News Detection	Cognitive Systems Research	posts / articles? 	(C.i) semantic embeddings generated by GloVe	2016 U.S. presidential election; unsupervised models possibly more effective than supervised models	source undisclosed	undisclosed	(2.iii) CNN 	(3.i) text contents, including title; (3.iii) author name	undisclosed	Accuracy 98.36%	none described	none described		FALSE
089	2020	Kapusta, Jozef; Benko, Ľubomír; Munk, Michal	Fake News Identification Based on Sentiment and Frequency Analysis	Innovation in Information Systems and Technologies to Support Learning Research	articles	(A.i) stylometry; sentiment	comparison of text characteristics of real and fake news	two datasets that contained a total of 28 870 articles	n/a	uses significance test to determine if count of sentimental words/phrases correlates with real or fake news	(3.i) text sentiment	undisclosed	n/a	n/a	n/a	n/a	FALSE
090	2020	Kartal, Yavuz Selim; Guvenen, Busra; Kutlu, Mucahid	Too Many Claims to Fact-Check: Prioritizing Political Claims Based on Check-Worthiness	arXiv:2004.08166 [cs]	claims	(A.i) stylometry; content analysis; (A.ii) topic modeling; (C.iii) 'checkworthiness'	mentions 2016 u.s. election; mentions that manual fact-checking is too slow	datasets used in Check That! Labs competitions in 2018 and 2019	undisclosed	BERT embeddings 	(3.i) topic; handcrafted word list; verb tense; adjective and superlative choice (authors frame topic narrowness as a strength of their method, since controversy of a topic depends on the society'	undisclosed (but mentions immigration, elections, etc)	ablation and use-one-only testing; performance at most 25% on any one task (word embeddings performed best on use-one-only)	not discussed; authors do mention wanting to use a 'weak supervised approach'	not discussed		FALSE
091	2019	Katsaros, D and Stavropoulos, G and Papakostas, D	Which machine learning paradigm for fake news detection (2019)	IEEE	claims; articles	[evaluates ML approaches to detection]	reality vertigo' for 'protecting less educated persons'; mentions 2016 presidential elections	LIAR, Kaggle, Signalmedia			claim that TF-IDF is more effective than word embeddings for representing text						FALSE
092	2020	Kaur, S and Kumar, P and Kumaraguru, P	Automating fake news detection system using multi-level voting model	Soft computing	articles	(A.i) text features 	increasing speed of fact-checking on social networks	articles downloaded from News Trends, Kaggle and Reuters websites	66/33 train/test	(2.ii) LR, SVM	feature extraction with TF-IDF, CV, HV. (3.i) these are all text features	mixed news topics	LinearSVC had accuracy 93.6 on NewsTrends dataset				TRUE
093	2020	Kesarwani, A and Chauhan, SS and Nair, AR	Fake news detection on social media using k-nearest neighbor classifier	International conference on advances in computing and communication engineering	users	(U.i) user account semantics; (U.ii) sharing patterns	consideration of 'secondary information,' including social behaviors, in determining news veracity	Buzzfeed News dataset, containing Facebook data	none disclosed	(2.ii) KNN	(3.ii), (3.iii) account_id, post_id, share_count, comment_count, Rating	mixed topic	accuracy of 79% 	none described	none described		FALSE
095	2017	Kim, Antino; Moravec, Patricia; Dennis, Alan	Behind the Stars: The Effects of News Source Ratings on Fake News in Social Media	SSRN Electronic Journal	articles; users (ratings)	[survey study; authors ask users to qualify how ratings influence their perception of news events]	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	FALSE
096	2018	Kim, Jooyeon; Tabibian, Behzad; Oh, Alice; Schölkopf, Bernhard; Gomez-Rodriguez, Manuel	Leveraging the Crowd to Detect and Reduce the Spread of Fake News and Misinformation	Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM '18	articles; user behaviors	(A.i) (C.iii) 'checkability' of news articles	effectiveness of user flagging of misinfo content	Twitter and Weibo datasets	none disclosed	(2.iv) marked temporal processes	(U.ii) user flagging activity 	mixed topic		datasets and method: https://github.com/Networks-Learning/curb			FALSE
099	2018	Kotteti, CMM and Dong, X and Li, N and Qian, L	Fake news detection enhancement with data imputation	IEEE	articles	(A.i) undisclosed text features	imputation of missing data in training	LIAR 	12,836 records in which training set has 10,269 records, validation and testing sets have 1,284 and 1,283 records	(2.ii) SVM, DT, GB	TF-IDF to extract (3.i) text features	mixed topics	MLP achieves accuracy 0.416 on validation set	n/a	n/a	n/a	TRUE
100	2022	Kou, Ziyi; Shang, Lanyu; Zhang, Yang; Wang, Dong	HC-COVID: A Hierarchical Crowdsource Knowledge Graph Approach to Explainable COVID-19 Misinformation Detection	Proceedings of the ACM on Human-Computer Interaction	claims (COVID-related)	(C.i) veracity of COVID-19-related statements	addressing COVID-19 misinformation	CoAID and CONSTRAINT: CoAID is a health misinfo dataset that contains health misinfo articles; CONSTRAINT contains COVID-related tweets	50% test, 20% validation, 30% test; 10 fold x validation	(2.iv) knowledge graph; proposes hybrid human-AI approach to fact checks using hierarchical knowledge graph constructed from AMT-submitted SPO statements	(3.i) essentially dual knowledge graph representation of medical info constructed from expert and non-expert AMTers (CKGC); requires them to enter information in the form of SPO statements for article-level and topic-level statements (specific and abstract, two levels of generalizability/granularity); these relationships are then used to construction a hierarchical knowledge graph (CHKG)  	COVID misinformation	evaluation against other methods (dEFEND, MVAE, KMGCN, deterrent); otperforms other methods with accuracy near 90%	n/a	n/a	n/a	FALSE
102	2019	Krishnan, S.; Chen, M.	Cloud-Based System for Fake Tweet Identification	2019 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)	posts (tweets)	(U.ii) post veracity from account credibility	misinformation about Hurricane Sandy, Chile earthquake on Twitter	244 websites tagged as “bullshit” by the BS Detector Chrome extension	undisclosed	(2.ii) J48, SVM	(3.i) tweet contents; (3.iii) number of friends, number of followers, friend follower ratio	undisclosed	undisclosed	none described	none described		FALSE
103	2020	Kudarvalli, Harika; Fiaidhi, Jinan	Detecting Fake News using Machine Learning Algorithms	https://www.techrxiv.org/articles/preprint/Detecting_Fake_News_using_Machine_Learning_Algorithms/12089133	posts (tweets)	(C.i) post contents; (U.ii) user verified status	latest presidential elections'	25K tweets extracted from Twitter API for tweets relating to Trump, politics, and coronavirus	undisclosed	(2.ii) LR, SVM, NB, LSTM	(3.i) keywords identified through tokenization process; (3.ii) user verified status	Trump, political news, coronavirus	94% accuracy for LR; 93% accuracy for SVM	none described	none described		FALSE
104	2019	Kumar, S and Asthana, R and Upadhyay, S and Upreti, N and Akbar, M	Fake news detection using deep learning models: a novel approach	Trans Emerg Telecommun Technol	articles	(A.i) article contents	classifying fake news from real news	1356 news instances from PolitiFact	60/40 train/test	(2.ii) LR, SVM	(3.i) text features with GloVe	U.S. political news	average accuracy 88.78%				TRUE
105	2016	Kumar, Srijan; West, Robert; Leskovec, Jure	Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes	Proceedings of the 25th International Conference on World Wide Web - WWW '16	articles	(W.i) appearance features (plain-text length, plain-text to markup ratio, wiki link density), link network features (ego-network clustering coefficient), support features (number of prior mentions, time of first prior mention, creator of first prior mention), editor features (number of prior edits and editor age)		set of all hoax articles ever created on wikipedia (20k)	classification of articles as hoax or not	random forests	yes -- hoax detection		91%; but 90% of hoaxes flagged anyway within 1 hr of patrolling by editors; but then again human subjects had 63% on a classification task	automated flagging of bogus wiki articles		approximately as good as human editors; better than human editors in the testing scenario proposed in the study	FALSE
106	2020	Kurasinski, L.; Mihailescu, R.-C.	Towards Machine Learning Explainability in Text Classification for Fake News Detection	2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)	article	(C.i) (A.i) text semantics and style/genre		Fake News Corpus dataset: over nine million texts labeled as one of 11 categories: false, satire, bias, conspiracy, state, junksci hate, click bait, unreliable, political, true		investigation of two diff models: 1) CNN and bidirectional recurrent neural networks, and 2) BERT	yes -- text classification; BERT, CNN - BiDirLSTM		85% for BiDir and 52% for BERT	authors state that they're primarily interested in investigating the explainability of two popular models	not really (only state that they're interested in considering other info domains in the future)		FALSE
108	2013	Kwon, Sejeong and Cha, Meeyoung and Jung, Kyomin and Chen, Wei and Wang, Yajun	Prominent Features of Rumor Propagation in Online Social Media	IEEE Int'l Conference on Data Mining	posts (tweets); users 	(C.i) sentiment; (N.i) temporality	rumor diffusion on social media	three and a half years worth of Twitter data, comprising 104 viral events, each of which involves at least 60 posts. Four human coders annotated each viral event.	undisclosed	(2.ii) DT, RF, SVM	(3.i) text sentiment from LIWC; (3.ii) friendship and diffusion networks	mixed-topic Twitter rumors	90% accuracy, 92% precision, 88% recall, and 88% F1 for RF using all features	none described	none described		FALSE
109	2021	Lee, Nayeon; Li, Belinda Z.; Wang, Sinong; Fung, Pascale; Ma, Hao; Yih, Wen-tau; Khabsa, Madian	On Unifying Misinformation Detection	arXiv:2104.05243 [cs]	articles 	(C.i) (W.i) (A.i) content, infrastructure, and style features		(FakeNews/Webis and BASIL datasets); posts (PHEME dataset of tweets); infrastructure (Clickbait dataset; contains news headlines)									FALSE
110	2020	Lennart van de Guchte, Stephan Raaijmakers, Erik Meeuwissen & Jennifer Spenader 	Near Real-Time Detection of Misinformation on Online Social Networks	6th Multidisciplinary International Symposium on Disinformation in Open Online Media	post	(C.i) stylometry; (N.i) networks	real-time detection of misinformation on Twitter	novel Twitter dataset scraped using NewsAnalyzer and Hoaxy	80/20 train/test, 10-fold x validation	(2.ii) LSTM, (2.iii) RNN	(3.i) tweet contents, including punctuation, hashtags; (3.iii) number of friends, number of followers, friend follower ratio	political news sourced from Hoaxy and NewsAnalyzer sites	LSTM-ALL achieves accuracy 93% on a 1-min detection deadline	none described	none described		TRUE
111	2014	Li, Jiwei and Ott, Myle and Cardie, Claire and Hovy, Eduard.	Towards a general rule for identifying deceptive opinion spam. 	Proceedings of the 52nd annual meeting of the association for computational linguistics	posts (reviews)	(C.i) review contents; 	detection of fake product reviews ('opinion spam')	domain expert deceptive opinion spam (Employee), crowdsourced deceptive opinion spam (Turker), and truthful Customer reviews (Customer) on hotels, doctors, and restaurants	undisclosed	(2.ii) SVM	(3.i) deceptive language features, including features from LIWC	restaurant, doctor, and hotel reviews	model achieves 0.799 accuracy, 0.794 precision, 0.758 recall, and 0.766 F1 on NYC-Hotel 	none described	none described		FALSE
112	2019	Lim, Munyeong; Park, Sungbum	A Study on the Preemptive Measure for Fake News Eradication Using Data Mining Algorithms : Focused on the M Online Community Postings	Journal of Information Technology Services	posts (from M community forum)	[korean language paper]	--	--	--	(2.ii) SVM, FR, LR	--	--	RF achieves TPR 0.70, FPR 0.307, precision 0.70, and recall 0.70				FALSE
113	2019	Lin, X and Liao, X and Xu, T and Pian, W and Wong, KF	Rumor detection with hierarchical recurrent convolutional neural network	CCF international conference on natural language processing and chinese computing	posts (tweets and weibo posts); events (collections of posts)	(C.i) post contents; (N.ii) network propagation patterns	2015 rumors about shootings and kidnappings near Veracruz	Twitter and Sina Weibo datasets produced by Ma et al. in 2016; Weibo dataset contains 4664 events and Twitter dataset contains 992 events	undisclosed	(2.iii) Hierarchical RNN	(3.i) text features, including length of post; (3.iii) user features, including followership and verified status	mixed rumoring topics	SVM-TS model achieved accuracy of 85.7% and 71.6% i	none described	none described		FALSE
114	2018	Liu, Q and Yu, F and Wu, S and Wang, L	Mining significant microblogs for misinformation identification: an attention-based approach	ACM Trans Intell Syst Technol	claims (tweets and weibo posts)	(C.i) text features and (U.ii) user features	disappearance of MH370; early detection of misinformation	Twitter and Sina Weibo datasets 	10% for tuning; 68/22 train/test	(2.iii) CNN	(3.i) text features; (3.iii) user features	mixed rumoring topics; Chinese news	AIM achieves accuracy 94%, precision 92%, 95% recall, and 93% f1 on misinformative posts	none described	none described		TRUE
115	2020	Liu, Y and Wu, YFB	Fned: a deep network for fake news early detection on social media	ACM Trans Inf Syst	claims (tweets); articles	(C.i) text features and (U.ii) user features from combinations of users’ text response and their corresponding user profiles, 	rapid detection of misinformation	Twitter (Twitter15) and Sina Weibo (Weibo16) datasets	5 fold x validation; 3 folds for training and 1 for testing	(2.iii) CNN	(3.i) text features; (3.iii) user features, including verified status, gender, location info	mixed rumoring topics; Chinese news	FNED achieves accuracy 99%, precision 98%, recall 98%, F1 98% on Twitter15 and accuracy 94%, precision 93%, recall 95%, and f1 94% on Weibo16	none described	none described		FALSE
116	2018	Liu, Yang; Wu, Yi-Fang Brook	Early Detection of Fake News on Social Media Through Propagation Path Classification with Recurrent and Convolutional Networks	AAAI	claims; story	(U.ii) user features; (N.i) propagation patterns 	early detection of misinformation	Twitter (Twitter15, Twitter16) and Sina Weibo datasets	10% for tuning; 68/22 train/test	(2.iii) RNN/CNN	(3.ii) network features, including timestamped interactions on social graphs; (3.iii) user features, including verified status, gender, location info	mixed rumoring topics; Chinese news	achieves accuracy 85% and 92% on Twitter and Sina Weibo respectively in 5 minutes after it starts to spread	none described	none described		TRUE
117	2017	Long, Y and Lu, Q and Xiang, R and Li, M and Huang, CR	Fake news detection through multi-perspective speaker profiles	Proceedings of the eighth international joint conference on natural language processing	articles; users	(C.i) lexical features	improving content-based detection with LSTMs	LIAR	80/10/10 train/tune/test	(2.iii) LSTM	(3.i) lexical features, (U.i) speaker features	mixed news	achieves accuracy 0.378 without attention, 0.385 with attention				TRUE
118	2017	Ma, Jing; Gao, Wei; Wong, Kam-Fai	Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning	Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)	claims (tweets)	(N.i) propagation patterns	Trump-related rumor spread in 2016	Twitter15 and Twitter16 datasets by Liu et al. and Ma et al.	undisclosed	(2.iv) Propagation tree kernel on diffusion graphs	undisclosed: 'Due to the complex nature of information diffusion, explicitly defining discriminant features based on propagation structure is difficult and biased.' Prop. trees compared to those of known rumors.	mixed rumoring topics	achieves accuracy 75% overall, 83% acc on non-rumors, 70% accuracy on false rumors, 77% on true rumors, 73% on unverified rumors for Twitter 15. 	none described	none described		FALSE
119	2010	Magdy, Amr and Wanas, Nayer	Web-based Statistical Fact-Checking of Textual Documents	Proceedings of the 2nd Int'l Workshop on Search and Mining User-generated Contents	articles	content ground-truth	fact extraction'	 The New York Times Annotated Corpus datase		Search is used thereon to validate the support available for these elements online, leading to assigning an overall score for each document'	undisclosed	mixed topics	not classification results; statistical scores from fact extraction				FALSE
120	2017	Maity et al. 	Detection of sockpuppets in social media	CSCW	users	(U.i) user account metadata semantics	fake followers of the 2016 U.S. presidential election on Twitter. poster presentation	most recent 3200 tweets and retweets from 77186 followers of Donald Trump and 46023 followers of Hillary Clinton.	3400 accounts across all twitter data randomly selected and manually annotated; 98 of these were identified as sockpuppet accounts	(2.ii) SVM, LR, RF	(3.ii) retweets, shares, regularity of tweets, followership (3.iii) verified status, profile creation date, location	2016 U.S. presidential candidate news and rumors	accuracy 90.98% and recall of 0.88 	none described	none described	none described	FALSE
123	2009	Mihalcea, Rada; Strapparava, Carlo	The lie detector: explorations in the automatic recognition of deceptive language	Proceedings of the ACL-IJCNLP 2009 Conference Short Papers on - ACL-IJCNLP '09	article	stylometrics		three datasets: articles on death penalty, articles on abortion, and articles on 'best friend' (authors created their own by asking subjects to think of a lie, then negate it; or to take an existing news article and tweak it)	deception detection by topic; cross-domain testing performed by training on two topics and testing on the third	(2.ii) NB, SVM	LIWC word classes for psycholinguistic analysis; words were tokenized and stemmed; SVM or naive bayes classifier applied. 		70%; 10 fold x-validation				FALSE
124	2015	Mihaylov et al.	Finding opinion manipulation trolls in news community forums	CoNLL	users	(U.ii) interaction statistics (and how these compare to those of known trolls)	opinion manipulation during crisis in Ukraine	crawled the largest Internet community forum of a Bulgarian media, that of Dnevnik.bg. trolls are users who were called such by at least n distinct users, and non-trolls have never been called so. user must have at least 100 comments. resulting dataset has 317 trolls and 964 non-trolls.'	5-fold x validation; splits not specified	(2.ii) SVM	(3.ii) upvotes and downvotes given and received on comments; (3.i) similarity between comments and publications, given by embedding cosine similarity	Bulgarian news topics	accuracy 90.63% and improvement of 15.38% over majority class baseline	none described	none described	majority class baseline difference  reported	FALSE
125	2015	Mihaylov et al.	Exposing paid opinion manipulation trolls in news community forums	RANLP	users	(U.ii) interaction statistics (and how these compare to those of known trolls)	2013-2014 Bulgarian protests against the Oresharski cabinet; allegations that ruling Socialist party was paying Internet trolls with EU Parliament money	training set comprises 314 “mentioned” troll with 150 posts or more, to which 314 non-trolls were added, also with 150+ posts.	authors train on 'mentioned' trolls and test on known paid trolls	(2.ii) SVM	(3.ii) upvotes and downvotes given and received on comments; (3.i) similarity between comments and publications, given by embedding cosine similarity	Bulgarian political news	100% precision and 75% recall on 8 testing examples	none described	none described		FALSE
128	2018	Monther Aldwairi, Ali Alwahedi	Detecting Fake News in Social Media Networks	Procedia Computer Science	sites	(C.i) headline semantics; (W.i) URL syntax; infrastructure	clickbait as a vector for misinfo spread	Authors scraped Reddit, Forex, and Facebook for URLs	10 fold x-validation	(2.ii) RF, NB, LR, RT	(3.i) Semantic and syntactical features: presence of exclamation points and question marks, all words capitalized. (3.iv) duration of page visit from users	mixed topics	LR achieves 99.4% precision, 99.3% recall, 99.3% f measure, and 99.5% ROC	none described	none described		FALSE
129	2019	Monti, Federico and Frasca, Fabrizio and Eynard, Davide and Mannion, Damon and Bronstein, Michael	Fake News Detection on Social Media using Geometric Deep Learning	arXiv	articles	(N.i) propagation patterns	incorporation of context into content signals	news stories, verified by professional fact-checking organizations, that were spread on Twitter		(2.iii) RNN/CNN	(3.i) content, (3.iii) user profile and activity, (3.ii) social graph, and news propagation		92.7% ROC AUC	https://github.com/YingtongDou/GCNN			FALSE
130	2022	Mughaid, A., Al-Zu’bi, S., AL Arjan, A. et al.	An intelligent cybersecurity system for detecting fake news in social media websites.	Soft Computing	website	(W.i) website reputation 	2020 U.S. presidential election	Kaggle	split not disclosed	(2.i) cosine similarity between text embedding representations of articles	(3.i) TF-IDF representations of article title, text, subject, publication date. (3.iv) website rank as determined by Alexa and Rankapi	mixed U.S. news	authors claim accuracy over 0.90 using LR; 'the ML classified six news as real and four as fake, but the results were better after inputting the same news into the proposed system' -- this is a very small test set	none described	none described	comparison to RF, SVM, NB, KNN	FALSE
131	2012	Mukherjee, Arjun and Liu, Bing and Glance, Natalie	Spotting fake reviewer groups in consumer reviews. 	Proceedings of the 21st International Conference on World Wide Web.	articles (reviews); users (reviewers)	(C.i) overwhelmingly positive language in reviews; (U.ii) user features; (N.i) propagation patterns 	detecting coordinated group of spam reviewers	53,469 reviewers, 109,518 reviews and 39,392 products on Amazon	2431 groups into the development set, D with 431 groups (randomly sampled) for parameter estimation and the validation set, V with 2000 groups	(2.ii) SVMRank. GSRank?	(3.i) Linguistic features: language having zero caveats, that is full of empty adjectives, contains purely glowing praises with no downsides; (3.iii) individual and group reviewer features; (3.iv) reviews left within a short period of time of each other, etc.	mixed product reviews	all features together (linguistic, group and individual reviewer features) achieved AUC 0.86 under Rank Boost	none described	none described		FALSE
132	2021	Nasir, Jamal Abdul and Khan, Osama Subhani and Varlamis, Iraklis	Fake news detection: a hybrid CNN-RNN based deep learning approach	Int'l journal of information management data insights	articles (news on the syrian war)	(A.i) style and text contents		FA-KES: 804 news articles written about the Syrian war (426 true and 376 are fake); full body, headline, date, location, and news source  ISOT: 45k news articles, evenly split between true and false; true articles collected from Reuters, fake from various sources flagged as fake by Wiki and Politifact; full article body, title, date, and topic; between 2016 and 2017; topics are politics and world news	80/20 train/test 	(2.iii) LSTM ; hybrid-RNN / CNN ; CNN for feature extraction and RNN for long-term dependencies 	word embedding 	international news	validated on two fake news datasets (ISO and FA-KES)' -- this is possibly an abuse of 'validated,' though (it's not x-validation)	https://onlineacademiccommunity.uvic.ca/isot/2022/11/27/fake-news-detection-datasets/; dataset: https://zenodo.org/record/2607278 ; method: https://drive.google.com/file/d/106fx5R8gQtmfFmqVM1aZ_D8mQKTVEI57/view	not really ... just ISOT and FA-KES		TRUE
133	2019	Nguyen, Duc Minh; Do, Tien Huu; Calderbank, Robert; Deligiannis, Nikos	Fake News Detection using Deep Markov Random Fields	Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)	articles	(A.i) article features (undisclosed)	correlations between articles understudied	Weibo 		(2.iii) Markov Deep fields	(3.i) word2vec embedding of article contents		Achieves acc 0.800 prec 0.803 rec 0.803 f1 0.799 on twitter data				TRUE
134	2012	Nguyen, Nam P and Yan, Guanhua and Thai My T and Eidenbenz, Stephan	Containment of misinformation spread in online social networks.	Proceedings of the 4th annual acm web science conference	networks	(N.i) networks	swine flu tweets on Twitter in 2009; selection of small subset of users with 'good' information to counter spread of bad information	NetHEPT information diffusion dataset; Facebook network dataset 	none disclosed	(2.iv) 'Greedy viral stopper' graph algorithm	(3.ii) followership, social graph representations among users	mixed topic	GVS prevents dissemination of misinfo more effectively than random baselines on tests of Facebook data and the NetHEPT dataset	none described	authors mention that algo takes 5 hrs to converge; not ideal for late-breaking news	compared to High degree, DiscountIC, and Page Rank algorithms	FALSE
135	2020	Ni, B and Guo, Z and LI, J and JIang, M	Improving generalizability of fake news detection methods using propensity score matching	arXiv	claims (from PolitiFact and GossipCop)	[addresses feature selection for misinfo detection methods]	authors hope to avoid topic-specificity and in-domain limitations. 'the main objective of ou work is not to improve the absolute performance of fake news detection. here we employ content-based features only but our proposed methods can be generalized to other types of features if causal relationships exist'	FakeNewsNet dataset; testing on Politifact and GossipCop datasets	trained on Politifact; evaluated on GossipCop	propensity-score matching to identify generalizable features instead of document frequency	(3.i) text features etc	political news; celebrity gossip	better than baseline (Politifact and GossipCop datasets); about 68% accuracy.		authors imply that non-text features can also be used ...		FALSE
136_e	2017	Nied, A Conrad and Stewart, Leo and Spiro, Emma and Starbird, Kate	Alternative narratives of crisis events: Communities and social botnets engaged on social media	Proceedings of the 2017 ACM conference on computer supported cooperative work and social computing companion	users; networks	(N.i) networks	nature of communities engaging in discussions of alternative narratives of crisis events; poster pres	30,684 total tweets on UCC shooting and paris attacks obtained through Twitter API		n/a	(3.ii) followership, pairwise social graph representations among users; (3.i) semantics of account metadata and posts	UCC shooting and paris attacks obtained through Twitter API	authors identified some user groups whose unifying trait was geography, political ideology, and contemporary movements. some 10% of accounts predicted to be bots	none described	none described	none described	FALSE
137	2020	Niraj Sitaula, Chilukuri K. Mohan, Jennifer Grygiel, Xinyi Zhou & Reza Zafarani 	Credibility-Based Fake News Detection 	Disinformation, Misinformation, and Fake News in Social Media	articles; users (author reputation)	(U.i) author reputation	detecting fake news by assessing author credibility	BuzzFeed news, PolitiFact	10-fold x validation	(2.ii) SVM, LR, RF, AdaBoost, NB, GB	(3.ii) author credibility signals, including affiliation/byline and prior authorship of a true-labeled article; (3.i) sentiment expressed in article body	U.S. political news	LR achieves F1 micro 0.80, F1 macro 0.80, and F1 weighted 0.80				FALSE
138_e	2019	Norregaard, Jeppe; Horne, Benjamin D.; Adali, Sibel	NELA-GT-2018: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles	arXiv:1904.01546 [cs]	articles; dataset	n/a	n/a	introduces new dataset	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	FALSE
139	2020	Nguyen, Van-Hoang and Sugiyama, Kazunari and Nakov, Preslav and Kan, Min-Yen	FANG: Leveraging Social Context for Fake News Detection Using Graph Representation	CIKM '20	claims (tweets)	(N.i) propagation patterns	faster RL-based approach to misinfo detection on graphs 	previously published Twitter datasets: PHEME, Twitter16, FakeNewsNet	undisclosed	(2.iii) GNN	(3.i) TF-IDF representations of user profiles and website text; relative stance (3.iv) user-user and user-source interactions represented as edges in a social graph	mixed topics	FANG achieves AUC 0.75	none described	none described	https://github.com/nguyenvanhoang7398/FANG	FALSE
141	2019	Nyow, Ning Xin; Chua, Hui Na	Detecting Fake News with Tweets’ Properties	2019 IEEE Conference on Application, Information and Network Security (AINS)	posts	(W.i) URL semantics; (C.i) tweet semantics	speed and volume of social media misinformation	23206(?) tweets drawn from Twitter API	60/40 train/test	(2.ii) SVM, Naïve Bayes (NB), Logistic Regression, Decision Tree and Random Forest (RF).	(3.ii) Tweet-specific attributes (i.e. t_givenids, p_availids, t_retweet and t_fav); (3.iv) News-specific attributes (i.e. url_protocol, url_level, url_www and title_words);	mixed topics	RF achieves 98.6% accuracy, 95.4% recall, and 97.2% F1 using both categories of features	none described	none described		FALSE
143_f	2020	Pacheco, Diogo; Hui, Pik-Mai; Torres-Lugo, Christopher; Truong, Bao Tran; Flammini, Alessandro; Menczer, Filippo	Uncovering Coordinated Networks on Social Media: Methods and Case Studies	ICWSM 2021	networks; user behaviors	(N.i) networks	detection of coordinated social media accounts	BEV Twitter dataset by Yang, Hui, and Menczer 2019; contains 59M accounts	n/a	(2.iv) graph algorithm for extracting clusters of users	(3.i) contents of posts and reshares; (3.ii) followership and propagation; (3.iii) account name and bio information	Hong Kong protests, crypto scams, U.S. elections, Syrian civil war	Authors evaluate all four scenarios and different targets, including presence of hashtags, synchronized actions, and co-retweets. Crypto network detection was low-precision because dataset  contains  a  large  portion  of  tweets  unrelated  tocryptocurrencies — even though they too are coordinated. 	none described	authors disclaim that their method should be used in conjunction with individual-level misinfo evaluations	none described	FALSE
144	2019	Park, Sung Soo; Lee, Kun Chang	A Comparative Study of Text analysis and Network embedding Methods for Effective Fake News Detection	Journal of Digital Convergence	articles; networks	(A.i) (N.ii) stylometrics; networks	comparison of common ML models and word embedding models	WELFake dataset	80/20/20(?) test set is 20% of the training set -- a source of leakage	(2.ii) SVM, (2.iii) LSTM 	(3.i) semantic features encoded by Bag Of Words, Word2Vec, Doc2Vec, Global Vectors	mixed topics	Ft:bert-adam achieved 97.5% accuracy				FALSE
145_e	2021	Pelrine, Kellin; Danovitch, Jacob; Rabbany, Reihaneh	The Surprising Performance of Simple Baselines for Misinformation Detection	arXiv:2104.06952 [cs]	posts (PHEME dataset of tweets; Twitter15 and Twitter16); articles (FakeNewsNet news checked by PolitiFact and GossipCop); CoAID (tweets, articles, claims)	meta-analysis of model choice for detection tasks; finds that fine-tuning transformer models produces performance evals on par with sophisticated models. Investigates dependencies in the Twitter16 dataset that produce deceptively high accuracy scores	--	--	for evaluation. All evaluation metrics are averaged over 10-fold	--	--	--					FALSE
146	2017	Pérez-Rosas, Verónica; Kleinberg, Bennett; Lefevre, Alexandra; Mihalcea, Rada	Automatic Detection of Fake News	arXiv:1708.07104 [cs]	article	(A.i) 'linguistic differences' (stylometrics, 		authors construct their own fake news corpus (240 articles generated AMT, emulating style of journalists); authors collect 240 real news articles from e.g. NYT, MSNBC, etc -- also construct a Celebrity news corpus with 100 real and 100 fake news articles. two new datasets cover 'seven different news domains'	true/false	(2.ii) linear SVM classifier and five-fold x-validation	yep		0.74 on average across all features on FakeNews; 0.73 across all features on Celebrity	not available https://docs.google.com/document/d/1EhpQup-UW7KShA8NAYIYl9-PYpgrlhkh-MBVQPxtbAU/edit	comparable to human ability to detect deception'	human baseline accuracy'	FALSE
147_e	2020	Pierri, Francesco; Piccardi, Carlo; Ceri, Stefano	Topology comparison of Twitter diffusion networks effectively reveals misleading information	Scientific Reports	networks; user behaviors	(N.ii) compares topologies of diffusion networks arising from non-misinfo and misinfo Twitter info cascades (tweets containing URLs to known misleading vs mainstream outlets); finds that 	(N.ii) propagation/information diffusion 	Tweets (from Twitter API) from known misinformation and mainstream URLs	cross validation (CV) on V	(2.ii) KNN, LR	(3.ii) WCC = Number of Weakly Connected Components; LWCC = Size of the Largest Weakly Connected Component; CC = Average Clustering Coefficient; DWCC = Diameter of the Largest Weakly Connected Components; SCC = Number of Strongly Connected Components; LSCC = Size of the Largest Strongly Connected Component; KC = Main K-Core Number	mixed news; U.S. political news	AUROC in the range 0.75–0.93	none described	none described		FALSE
149	2018	Popat, Kashyap; Mukherjee, Subhabrata; Yates, Andrew; Weikum, Gerhard	DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning	Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing	claims; articles (external evidence)	(C.i), (A.i) text veracity using features from external sources to corroborate or refute	aggregates source credibility scores with text features	Four existing collections of labeled claims from the following sources: Snopes, PolitiFact, NewsTrust, and SemEval (tweets). 	....the model is trained on 9-folds and the remaining fold is used as test data. When using the SemEval dataset, we use the data splits provided by the task’s organizers...' ; leakages maybe in feature selection? splits seem fine	(3.iii) NN	(3.i) Includes external, web-based evidence (argues that existing methods require rich feature modeling and lexicons) in an unsupervised model; 	Political news (draws from Politifact, Snopes, NewsTrust)	When using the Snopes, PolitiFact and NewsTrust datasets, we reserve 10% of the data as validation data for parameter tuning. We report 10-fold cross validation results on the remaining 90% of the data; the model is trained on 9-folds and the remaining fold is used as test data. When using the SemEval dataset, we use the data splits provided by the task’s organizers. The objective for Snopes, PolitiFact and SemEval experiments is binary (credibility) classification, while for NewsTrust the objective is to predict the credibility score of the input claim on a scale of 1 to 5 (i.e., credibility regression).	undisclosed	real world datasets'; SemEval Twitter dataset	compared to CNN-text, LSTM, LSTM-text, etc. Unclear why these in particular are SOTA though	FALSE
150	2017	Potthast, Martin; Kiesel, Johannes; Reinartz, Kevin; Bevendorff, Janek; Stein, Benno	A Stylometric Inquiry into Hyperpartisan and Fake News		article	(A.i) stylometrics; for first-pass detection of extremism and satire in writing		Buzzfeed-Webis fake news corpus	style and bias detection; mainstream vs niche news org detection		n-grams, stop words, readability, text length, LIWC, sentiment; 3-fold x-validation		satire prediction model achieves accuracy of 0.82; 0.75 for detecting hyperpartisanship; fact classification is dismal; better luck distinguishing hyperpartisan and real than real and fake; see paper for stats; 3-fold x-validation	as a supplement to fact-checking	none really	alas, we cannot claim to have solved fake news detection via style analysis alone'	FALSE
151	2017	Pratiwi, IYR and Asmara, RA and Rahutomo, F	Study of hoax news detection using naïve bayes classifier in Indonesian language	IEEE	articles			x		(2.ii) NB	(3.i) language features specific to hoaxes						FALSE
152	2020	Previti, Marialaura; Rodriguez-Fernandez, Victor; Camacho, David; Carchiolo, Vincenza; Malgeri, Michele	Fake News Detection Using Time Series and User Features Classification	Applications of Evolutionary Computation	posts (tweets); user behaviors	(U.i) leveraging tweet metadata (but not tweet text) to identify rumors	(N.ii) propagation patterns; (U.ii) user and post metadata	Label rumoring tweet dataset (from Vosoughi et al.) 	clustered by rumor; 10-fold x validation; train/test split undisclosed	(2.ii) RF (500 trees)	(3.ii) 'time-series' based features, including datetimes of original tweets and reshares; (3.iii) user features, including followership	known rumoring topics; mixed topics	accuracy 84.61%	none described	none described		FALSE
153	2011	Qazvinian, Vahed; Rosengren, Emily; Radev, Dragomir R; Mei, Qiaozhu	Rumor has it: Identifying Misinformation in Microblogs	Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing	posts (tweets)	(A.i) early detection of misinformation on microblogging sites; appears to conflate rumors and false information	(C.i) post semantics; (U.ii) user and post metadata	10,000 manually annotated tweets collected from Twitter from queries on keywords related to known rumoring narratives	5-fold cross-validation	L-BFGS for rumorous tweet ranking and retrieval	(3.i) content-based features, including unigrams for tweet contents, hashtags; (3.ii) network features, including reshares and likes	known rumoring topics; political and conspiracy-related topics	retrieval model achieves more than 0.95 in Mean Average Precision (MAP)	authors disclaim that detecting novel rumoring narratives is a much harder task	none described		FALSE
154	2018	Qian, Feng; Gong, Chengyue; Sharma, Karishma; Liu, Yan	Neural User Response Generator: Fake News Detection with Collective User Intelligence	Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence	article; text	(U.i); (C.i) user response and text contents	incorporating socia context with text signals	is aware that many other methods rely on propagation patterns that will only become available after a certain degree of virality has been achieved		(2.iii) TCNN-URG	public Weibo dataset; real news dataset (The Guardian, New York Times) and fake news dataset (NaturalNews); searched Twitter for user responses to each article URL		TCNN-URG performs above 80% for almost all tasks on Weibo; above 75% on all tasks on fake news detection dataset	therefore, we focus on early detection of fake news, and consider that only news article text is available at the time of detection, since additional information such as user responses and propagation patterns can be obtained only after the news spreads.' ; 'existing work on fake news detection perform poorly on early detection because most of themmainly utilize network-based information, such as user responses to news articles on social networks'	not really; 'assist in early detection'	not really	FALSE
155	2019	Ramezani, Maryam; Rafiei, Mina; Omranpour, Soroush; Rabiee, Hamid R.	News Labeling as Early as Possible: Real or Fake?	arXiv:1906.03423 [cs]	posts (tweets and weibo posts); events (collections of posts)	(N.ii) time-series representations of news spread	early detection of misinformation on social media sites	Sina Weibo with 2746818 users, 2351 real and 2313 fake events. Twitter with 381541 users, 493 real and 498 fake events	undisclosed	(2.iii) RNNs	(3.i) content-based features, including Word2Vec embeddings for tweet contents; (3.ii) one network feature: posting time; (3.iii) 8 user features, including verified status, followership stats, account age	known rumoring topics; Chinese news	Sina Weibo stats: 0.93 recall, 0.87 precision, 0.90 f1 on fake news; 0.86 recall, 0.92 precision, 0.89 f1 on real news	none described	none described		FALSE
156	2017	Rashkin, Hannah; Choi, Eunsol; Jang, Jin Yea; Volkova, Svitlana; Choi, Yejin	Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking	Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing	article	(A.i) stylometrics		labeled statements from PolitiFact	untrustworthy' text detection via identification of linguistic characteristics typical of satire, hoax, and propaganda	(2.ii) MaxEnt and Naive Bayes, LSTM	yes		65% FI on out-of-domain test set	no response		better than random'	FALSE
157	2019	Rasool, Tayyaba and Butt, Wasi Haider and Shaukat, Arslan and Akram, M. Usman	Multi-label fake news detection using multi-layered supervised learning (2019)	ICCAE	claims (LIAR dataset); articles	(C.i) veracity; (W.i) source credibility as a major contributor to accuracy	binary classifications insufficient to accurately label news; multi-class classification required	LIAR dataset (12836 news statements from various speakers in Politifact.com)	70/30 split; x validation 	supervised approach; 		pollitical news	testing on test set using SVM yielded accuracy 78/8%. accuracy overall on the full test set was 43.3%		none	mentions human checking accuracy (between 50-63%); benchmarks are Hybrid NNN , single level SVM, and decision tree methods which are all under 40%	FALSE
158	2020	Reddy, Harita; Raj, Namratha; Gala, Manali; Basava, Annappa	Text-mining-based Fake News Detection Using Ensemble Methods	International Journal of Automation and Computing	articles	(A.i) stylometry	misinfo written in such ways that make it increasingly difficult to detect	FakeNewsNet		(2.ii) RF, NB, SVM, LR and KNN	(3.i) stylometric and word2vec features	mixed news	RF achieves accuracy 82.5, precision 83.8, recall 80, F1 81.9	n/a	n/a	n/a	FALSE
159	2019	Reis, JCS and Correia, A and Murai, F and Veloso, A and Benevenuto, F	Supervised learning for fake news detection	IEEE intelligent systems	posts (facebook); users	evaluation of automated checking approaches; taxonomizes features and models	(C.i) post semantics; (U.ii) user and post metadata; (N.ii) network patterns	2282 BuzzFeed news articles related to the 2016 U.S. election labeled by journalists and enriched with comments associated with the news stories as well as shares and reactions from Facebook users	a fivefold split between training and test set, repeated ten times with different shuffled versions of the original dataset (a total of 50 runs).	(2.ii) KNN, NB, RF, SVM, and XGBoost (XGB).	(3.i) content-based features, including n-grams and LIWC; (3.ii) network features, including comment posting rate; (3.iii) user/source features, including bias and credibility; (3.iv) infrastructure features, including IP and geolocation from URL	2016 U.S. presidential election news	The best results were obtained by RF and XGB classifiers, statistically tied with 0.85 (+/-0.007) and 0.86 (+/-0.006)  for AUC, respectively.	none described	none described		FALSE
160	2021	Resnick, Paul; Alfayez, Aljohara; Im, Jane; Gilbert, Eric	Informed Crowds Can Effectively Identify Misinformation	arXiv:2108.07898 [cs]	articles	survey methods; user behaviors (links and queries)		crowd-sourced annotations									FALSE
161	2020	Santos, Roney and Pedro, Gabriela and Leal, Sidney and Vale, Oto and Pardo, Thiago and Bontcheva, Kalina and Scarton, Carolina	Measuring the Impact of Readability Features in Fake News Detection	acl	articles	(A.i) lexical diversity/complexity	contribution of readability features to misinfo classification	Fake.Br dataset	5-fold x validation	(2.ii) SVM	(3.i) word complexity, syllable count, etc	mixed	readability features achieve up to 92% accuracy				FALSE
162_f	2018	Ribeiro, Filipe N. and Henrique, Lucas and Benevenuto, Fabricio and Chakraborty, Abhijnan and Kulshreshtha, Juhi and Babaei, Mahmoudreza and Gummadi, Krishna P.	Media Bias Monitor: Quantifying Biases of Social Media News Outlets at Large-Scale	AAAI	website	(W.ii) site demographics: age, race, gender, income, national identity	using a site's advertiser interfaces to infer audience demographics and biases of a news site	20,448 pages categorized as news by Facebook	n/a	authors find fraction of users with different political leanings and multiply proportion by integers [-2, 2], from very liberal to very conservative, resulting in final bias score	infers biases from audience demographics	U.S. political news	correlation with survey-based approach was 0.97, indicating near-perfect matching	none described	none described	comparison to AllSides.com	FALSE
163	2021	Roitero, Kevin; Soprano, Michael; Portelli, Beatrice; De Luise, Massimiliano; Spina, Damiano; Della Mea, Vincenzo; Serra, Giuseppe; Mizzaro, Stefano; Demartini, Gianluca	Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent Misinformation about COVID-19	arXiv:2107.11755 [cs]	claims [not in-scope; not an automated detection approach]	(C.i) statement veracity determined via crowdsourced 	curbing COVID-19 misinformation	Politifact's COVID statement corpus	n/a	longitudinal survey study of crowdworkers rating COVID-19 misinformation	n/a		authors note performance differentials between experienced and novice raters and information published many days/weeks apart	yes; authors mention that performance degrades on information temporally distant from original benchmark set	authors mention need for 		FALSE
164	2020	Roitero, Kevin; Soprano, Michael; Portelli, Beatrice; Spina, Damiano; Della Mea, Vincenzo; Serra, Giuseppe; Mizzaro, Stefano; Demartini, Gianluca	The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation Objectively?	Proceedings of the 29th ACM International Conference on Information & Knowledge Management	claims	(U.ii) survey methods (crowd workers); user behaviors (search terms, clicks and mouse actions)	[not technically an automated classifier; evaluates human fact-checking process]		n/a	n/a	n/a	n/a					FALSE
165	2019	Roy, A and Basak, K and Ekbal, A and Bhattacharyya, P	A deep ensemble framework for fake news detection and classification	Proceedings of the 16th International Conference on Natural Language Processing	article	(A.i) text features	hand-engineered features not sufficiently comprehensive	Politifact; LIAR		(2.ii) CNN	(3.i) undisclosed text features (unsupervised model)		accuracy of 44.87%				FALSE
166	2014	Rubin et al 	Truth and deception at the rhetorical structure level		claims; articles	(A.i) stylometry; analyze sentence-level rhetorical structure in order to infer truthfulness of statements	discourse structure analysis as a means for distinguishing truth from deception; 'developing novel discourse-based tools to alert information users to potential deception in computer-mediated texts'	36 stories: 18 truthful, 18 false, written by AMTers.	-	crowdsourcing of texts and subsequent evaluation of RST clusters	analysis of discourse components offers a more fine-grained analysis of truth and falsity than binary labels applied to whole texts	unspecified ('36 unique personal stories')	no actual automated detection performed	not discussed (dataset also too small)			FALSE
167	2015	Rubin, Victoria and Conroy, Niall and Chen, Yimin	Towards News Verification: Deception Detection Methods for News Discourse	Proceedings of the Hawaii International Conference on System Sciences	article	LIWC etc		Bluff the Listener' show transcripts from NPR; each show contains three thematically-linked news reports, one of which is authentic, the other two are fake			yes	NPR transcripts	predictive model performance is 56%. 	n/a	n/a	our predictive model is not significantly better than chance (56% accuracy) though comparable to average human lie detection abilities (54%)	FALSE
168	2016	Rubin, Victoria and Conroy, Niall and Chen, Yimin and Cornwell, Sarah	Fake news or truth? Using satirical cues to detect potentially misleading news	Proceedings of the Second Workshop on Computational Approaches to Deception Detection	article	stylometry	linking satire cues to misinformation 	fake news from The Onion and The Beaverton, and true news from NYT and Toronto Star	satire as a proxy for misinformation	SVM	yes	satire 	90% precision and 84% recall	decreasing confidence in mainstream news; increasing reliance on alternative news sources; consumers and producers need ways to quickly distinguish true from false			FALSE
170	2017	Ruchansky, Natali; Seo, Sungyong; Liu, Yan	CSI: A Hybrid Deep Model for Fake News Detection	Proceedings of the 2017 ACM on Conference on Information and Knowledge Management	article	stylometrics; content; user; network; veracity of social media posts/articles from text, response, and user profile		Twitter and Weibo post datasets with user data; unclear if model is trained and tested on same data sets	80% of entire data as training set; 5% for tuning; remaining 15% for testing; Normalization of feature vectors a bit suspect ; 5-fold cross validation	lots of features ... 	Three categories: article text, user response, source users promoting article; method aims to use text, response, and source in conjunction because any one in isolation is insufficient. Authors consider three different models: CSI (Capture, Source, Integrate -- all features), CI (Capture, Integrate -- text features only) and CI-t (textual and temporal features only). 	mixed topic	0.892 accuracy on Twitter and 0.954 on Weibo	detection on social media platforms	none observed; no real-time testing mentioned		FALSE
171	2014	Sáez-Trumper, Diego	Fake tweet buster: a webtool to identify users promoting fake news ontwitter	HT	users	(C.i) image provenance; (U.i) account metadata	proposal for approach to id'ing users based on fake image content 	none disclosed	none described	none; reverse image search, age of account with post count, or manual identification	(3.i) user account identification requires account age and count of posts made	none described	none described	none described	none described	none described	FALSE
172	2019	Saikh, Tanik; Anand, Amit; Ekbal, Asif; Bhattacharyya, Pushpak	A Novel Approach Towards Fake News Detection: Deep Learning Augmented with Textual Entailment Features	Natural Language Processing and Information Systems	claims	(A.ii) text entailment		Fake News Challenge Dataset	n/a	(2.iii) NN	11 features, including synonyms, antonyms, longest common overlap, hypernym, hyponym, modality, overlapping tokens, cosine similarity, numerals		all features taken together have F1 score abotu 0.48		n/a		FALSE
173	2019	Sánchez-Junquera, Javier; Rosso, Paolo; Montes-y-Gómez, Manuel; Ponzetto, Simone Paolo	Unmasking Bias in News	arXiv:1906.04836 [cs]	articles (Potthast dataset)	stylometry											FALSE
174	2019	Schuster, Tal and Schuster, Roei and Shah, Darsh J. and Barzilay, Regina	Computational Linguistics	The limitations of stylometry for detecting machine-generated fake news	claims	(A.i) stylometry	authors test a stylometry detection method to show that stylometry and veracity detection are distinct tasks (and even LMs can do simple inversion edits to alter veracity without changing style). 	New York Times articles	unspecified	the Grover-Mega classifier, fine-tuned for the target task	text features; lexicosemantic features		classifier had 71% on classification task; human had 68% on same task; human with access to external references had 84% on their task			comparisons made to human rating performance	FALSE
175_e	2019	Seref, Michelle; Seref, Onur	Rhetoric Mining for Fake News: Identifying Moves of Persuasion and Disinformation	AMCIS 2019 Proceedings	posts; infrastructure (likes, shares, reposts)	(C.i) post semantics	research proposal for identification of rhetorical strategies used by true and misinformative news	BuzzFeed-Webis; LIAR	not reported	not reported	not reported	political news	not reported	none described	none described		FALSE
176	2019	Shah, Shamoz; Goyal, Madhu	Anomaly Detection in Social Media Using Recurrent Neural Network	Computational Science – ICCS 2019	posts	(N.ii) propagation patterns	detection of 'fake and anomalous' news events pertaining to 2016 U.S. presidential election	2016 U.S. presidential election results,' source and medium undisclosed	not reported; authors train classifier on results and test on predictions (severe leakage issue)	(2.ii) KNN, (2.iii) RNN	This data was presented as the number of votes the Democrat Party had won, as a percentage of the total votes.'	2016 U.S. presidential election	accuracy better than 80% for K = 10?	none described	none described		FALSE
177_e	2016	Shao, Chengcheng and Ciampaglia, Giovanni Luca and Flammini, Alessandro and Menczer, Filippo	Hoaxy: a platform for tracking online misinformation	Proceedings of the 25th international conference companion on world wide web	posts (tweets); users	(W.i) URL semantics	presents tool for tracking of misinfo tweets 	tweets containing URLs from two lists of Web domains: the first, fake news, covers 71 misinfo domains. We manually removed known satirical sources like The Onion. The second list is composed of the six most popular fact-checking websites: Snopes.com, PolitiFact. com, FactCheck.org, OpenSecrets.org, TruthOrFiction. com, and HoaxSlayer.com; 3 months of filtered tweets traffic from Oct 14, 2015 to Jan 24, 2016	n/a	n/a	(3.ii) likes and reshares; (3.iv) tweeted URL semantics	mixed news; political news	authors find that fact-checking tweets spread more slowly than misinfo tweets	none described	none described		FALSE
178	2018	Shao, Chengcheng and Ciampaglia, Giovanni Luca and Varol, Onur, and Flammini, Alessandro and Menczer, Filippo	The spread of low-credibility content by social bots	Nature communications	posts (tweets); articles	(U.ii) botness of Twitter accounts	social bots played a disproportionate role in spreading articles from low-credibility sources	14 million messages spreading 400 thousand articles on Twitter during ten months in 2016 and 2017	n/a	(2.ii) authors use Botometer, which is an RF model	(3.iii) Bot-ness score calculated by Botometer	mixed news; political news	Botometer AUC is 94%	none described	none described		FALSE
181	2017	Shiralkar, Prashant; Flammini, Alessandro; Menczer, Filippo; Luca Ciampaglia, Giovanni	Finding Streams in Knowledge Graphs to Support Fact Checking	IEEE	claims (subject-predicate-object)	(N.i) networks	networks of information flow identified on KGs can help fact-checkers surface 'relevant facts' that might help them refute or corroborate statements; this is an update to the Ciampaglia et al. method from {check year} because this method is aware of predicate semantics (whereas, in the Ciampaglia method, the presence of an edge only indicated the presence of a relationship in general)	DBPedia tuples		flow identification from DBPedia tples	SPO tuples; S and O nodes with P edges	NBA; NYT Bestsellers; Oscars; FLOTUS	accuracy nearly 100% on in-DBPedia relationships		none	compared to PredPath and Knowledge Linker, both KG-based methods. 	FALSE
183	2019	Shu, K and Bernard, H.R. and Liu, H	Studying fake news via network analysis: detection and mitigation	Emerging research challenges and opportunities in computational social network analysis and mining	posts; users; user behaviors	(N.i) propagation across friendship networks, user-source interactions	proposes network-based approach to misinfo detection. cites speed and volume of social media misinformation as motivation	n/a	n/a	(2.iii) RNNs	(3.i) post semantics; (3.ii) user characteristics; (3.iii) friendship networks and interactions between individual users and sources	n/a	n/a	none described	none described	n/a	FALSE
184	2018	Shu, K and Mahudeswaran, D and Wang, S and Lee, D and Liu, H	Fakenewsnet: a data repository with news content, social context and dynamic information for studying fake news on social media		articles; dataset	n/a	n/a	introduces new dataset	n/a	n/a	n/a	n/a	n/a	https://github.com/KaiDMML/FakeNewsNet	n/a	n/a	FALSE
186	2019	Shu, K and Zhou, X and Wang, S and Zafarani, R and Liu, H	The role of user profiles for fake news detection	Proceedings of the 2019 IEEE/ACM international conference on advances in social networks analysis and mining	users	(U.i) user account semantics; (U.ii) sharing patterns	new content detection not sufficient, as 'fake news is written to mimic true news'; short paper	FakeNewsNet dataset	undisclosed	(2.ii) RF	(3.iii) user profile image, political bias, and location. Feature extraction using LIWC, RST	U.S. political news	LIWC_UPF features attain accuracy 92.1%, precision 0.942, recall 0.897, and F1 0.919 on PolitiFact data	none described	none described	none described	FALSE
187	2019	Shu, Kai and Cui, Limeng and Wwang, Suhang and Lee, Dongwon and Liu, Huan	dEFEND: explainable fake news detection	Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery and data mining	articles; claims; user comments	(C.i) sentence contents; (U.ii) comments on posts	capturing contextual info (user comments) for misinfo detection	labeled Politifact and GossipCop news articles (politics and celebrity news)	undisclosed	(2.ii) DNN	news content and user comments: co-attention analysis; 	mixed news; political news	dEFEND achieves accuracy 0.904, 0.902 precision, 0.956 recall, 0.928 F1 on Politifact; 0.808 accuracy on GossipCop	https://www.dropbox.com/sh/rzczwopo618jyv2/AAA1mI2yvbt6TAfqpcxfjL8va?dl=0			FALSE
188_f	2017	Shu, Kai and Wang, Suhang and Liu, Huan	Exploiting tri-relationship for fake news detection	arXiv preprint	users; articles; context	(U.i) user account semantics; (U.ii) sharing patterns; (C.i) content	new content detection not sufficient, as 'fake news is written to mimic true news'; need to explore relationships between publishers, readers, and news writing	FakeNewsNet dataset	undisclosed	(2.ii) LR, NB, DT, RF	(3.i) contents of posts and reshares; (3.ii) social graph topology; (3.iii) account name and bio information	U.S. political news	RF and GradBoost achieve F1 > 0.80 on BuzzFeed and PolitiFact	none described	emulate real-time detection by introducing time delays to the FakeNewsNet dataset	comparison to other models	FALSE
189_e	2019	Shu, Kai; Liu, Huan	Detecting Fake News on Social Media	Synthesis Lectures on Data Mining and Knowledge Discovery	sources; authors		[this is a full textbook]										FALSE
190	2019	Shu, Kai; Wang, Suhang; Liu, Huan	Beyond News Contents: The Role of Social Context for Fake News Detection	Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining - WSDM '19	article; source	(U.i) news accuracy from user credibility; more credible users likely to form smaller clusters ... less credible users likely to form larger clusters; authors model a series of pairwise relationship (news-pub, user-news) but not all three; 		FakeNewsNet (BuzzFeed and PolitiFact)	80% for training; 20% for testing; process is performed 10 times over; (5 fold? not specified)	(2.ii) LR, NB, DT, RF, GB, xgboost, adaboost	`Social context' in addition to regular tweet content. RST (rhetorical structure theory), LIWC, Castillo, RST+Castillo, LIWC+Castillo		better than 0.8 on most tasks; presupposition of certain user behaviors -- e.g., lack of credibility assumed to be associated with larger user interactions clusters	early detection on social media': F1 score more than 80% within 48 hrs on both datasets	claim that user-outlet-publisher relations are vital to understanding news veracity	compare to 'SOTA' (e.g., Castillo)	FALSE
191	2018	Shu, Kai; Wang, Suhang; Liu, Huan	Understanding User Profiles on Social Media for Fake News Detection	2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)	source	(C.i) contents; (N.ii) networks; (W.iv) ux features	content detection alone not sufficient; not a classifier, but presents observations of differences beetween 'experienced' and 'naive' news readers	BuzzFeed and PolitiFact	n/a	n/a	(3.iii) user profile verified status, account age, posts; (3.ii) followership 	U.S. political news	n/a	n/a	n/a		FALSE
192	2020	Shu, Kai; Zheng, Guoqing; Li, Yichuan; Mukherjee, Subhabrata; Awadallah, Ahmed Hassan; Ruston, Scott; Liu, Huan	Leveraging Multi-Source Weak Social Supervision for Early Detection of Fake News	arXiv:2004.01732 [cs, stat]	users; posts	(U.i) user account semantics; (U.ii) sharing patterns	using weak signals from user and content engagements to detect fake news	FakeNewsNet dataset	undisclosed	(2.iii) CNN, TCNN, RoBERTa	(3.i) sentiment (higher stdev in user sentiment cores is weakly labeled fake news); bias; credibility; (3.ii) these labels are generated per group of users who interact with a piece of news	U.S. political news	CNN and RoBERTa with MWSS attain F1 near 0.80, accuracy > 0.76 for GossipCop; F1 and accuracy of 0.82 for PolitiFact	none described	none described	compare to TCNN-URG and EANN	FALSE
193	2021	Silva, Amila; Luo, Ling; Karunasekera, Shanika; Leckie, Christopher	Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multimodal Data	arXiv:2102.06314 [cs]	article	(N.i) cross-domain fact-checking of news articles; actual targets include propagation patterns		politifact, gossipcop datasets: about 269 fake and 230 real from politifact and 1269 fake and 2466 real from gossipcop; 135 fake and 1568 real from coAID	cross-domain fact-checking of news articles; actual targets include propagation patterns		yes		better than 0.8 on most tasks	real-world checking needs to happen on cross-domain texts		TO CHECK: does this assume a priori knowledge of factuality of individual domains? 	FALSE
194_e	2021	Simko, Jakub; Tomlein, Matus; Pecher, Branislav; Moro, Robert; Srba, Ivan; Stefancova, Elena; Hrckova, Andrea; Kompan, Michal; Podrouzek, Juraj; Bielikova, Maria	Towards Continuous Automatic Audits of Social Media Adaptive Behavior and its Role in Misinformation Spreading	Adjunct Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization	position paper (no classifier)	(A.ii) proposes automatic annotation of topics by topic and stance in order to perform audits of ranking and recommendation algorithms on social media platforms	spread of online misinformation fueled by opaque recommendations on social media platforms	n/a	n/a	n/a	(3.i) post topic, stance	n/a	n/a	none described	none described		FALSE
195	2017	Singh, V and Dasgupta, R and Sonagra, D and Raman, K and Ghosh, I	Automated fake news detection using linguistic analysis and machine learning 	International conference on social computing ... 	articles	(A.i) stylometry	rumors re Russian hacking of VT power grid; Macron's campaign financed by Saudi Arabia	dataset of 345 “valid” news articles. This dataset includes an equal number of news reports from three wellknown and largely respected news agencies: National Public Radio, New York Times, and Public Broadcasting Corporation	80/20 train/test	(2.ii) SVM	(3.i) LIWC word features	mixed news topics	87% accuracy	none described	none described		TRUE
196	2019	Singhal, Shivangi. 	SpotFake	https://drive.google.com/file/d/1bn2LJhFyr8vlhOd-aee2TGN4_-ZwdL93/view?usp=share_link	article	content		Twitter and Weibo data; ImageNet; visual and textual data; Tw dataset for training included 9k fake news tweets and 6k real news tweets; test set contains 2k news tweets		(2.iii) EANN, MVAE	yes		77.77% on twitter and 89.23% on Weibo; recall and f1 on real news is below 70% though	checking multimedia posts on social media platforms			FALSE
197	2021	Soprano, Michael; Roitero, Kevin; La Barbera, David; Ceolin, Davide; Spina, Damiano; Mizzaro, Stefano; Demartini, Gianluca	The Many Dimensions of Truthfulness: Crowdsourcing Misinformation Assessments on a Multidimensional Scale	arXiv:2108.01222 [cs]	claims	survey methods (source credibility, comprehensibility, etc)	binary classification too simplistic a model for labeling misinfo	PolitiFact and ABC datasets	n/a	AMTer to collect crowdsourced ratings	political leaning; age; income; education level	political news					FALSE
198_e	2017	Starbird, Kate	Examining the alternative media ecosystem through the production of alternative narratives of mass shooting events on twitter.	Proceedings of the 12th international aaai conference on web and social media	posts (tweets); article (external links out)	understanding alternative narratives/conspiracy theories about mass casualty events	interaction networks (domains)	pulled tweets from Twitter API using keywords gunmen,  gunshot,  gunshots,  shooters,  gun  shot,  gun  shots, shootings)  for  a  ten-month  period  between  January  1  and October  5,  2016.  This collection  resulted  in  58M  total tweets.  We  then  scoped  that data  to  include  only  tweets related  to  alternative  narratives  of  the  event—false  flag, falseflag, crisis actor, crisisactor, staged, hoax and “1488”.	n/a	authors developed a graph network of user interactions with alternative media sources	n/a	mass casualty events; U.S. politics	n/a	none described	none described		FALSE
200	2019	Stefanone, Michael A.; Vollmer, Matthew; Covert, Jessica M.	In News We Trust?: Examining Credibility and Sharing Behaviors of Fake News	Proceedings of the 10th International Conference on Social Media and Society	articles (from allsides.com)	(U.i) survey methods; user behaviors											FALSE
201	2017	Tacchini, Eugenio; Ballarin, Gabriele; Della Vedova, Marco L.; Moret, Stefano; de Alfaro, Luca	Some Like it Hoax: Automated Fake News Detection in Social Networks	arXiv:1704.07506 [cs]	posts (facebook); users	(U.ii) 'likes' from users on hoax pages 	speed and volume of social media misinformation	15,500 posts from 32 pages (14 conspiracy and 18 scientific), with more than 2,300,00 likes by 900,000+ users (Table 1). Among posts, 8,923 (57.6%) are hoaxes and 6,577 (42.4%) non-hoaxes. Pulled from Facebook Graph API	80/20 train/test; 5-fold x validation	(2.ii) LR	(3.ii) user likes on hoax and non-hoax page posts	mixed news; political news	LR achieves accuracy over 70%; authors describe this as 'good performance'	none described	none described	https://github.com/gabll/some-like-it-hoax	FALSE
202	2015	Tambuscio, Marcella and Ruffo, Giancarlo and Flammini, Alessandro and Menczer, Filippo	Fact-checking effect on viral hoaxes: a model of misinformation spread in social networks	Proceedings of the 24th Int'l Conference on WWW	users; networks	(N.ii) propagation and duration of hoaxes in social media networks	hoax detection; hoaxes regarded as viruses	not tested on real data	n/a	SIS epidemiological model (Susceptible-Infected-Susceptible)	(3.ii) spreading rate, (3.iii) gullibility, probability of verifying a hoax, probability of abandoning prior belief	n/a	n/a	n/a	n/a	n/a	FALSE
206_e	2018	Thorne, James; Vlachos, Andreas; Christodoulopoulos Christos; and Mittal Arpit	FEVER: a large-scale dataset for Fact Extraction and VERification	arxiv	claims; dataset	(C.i) linguistics	[introduces a popular dataset]	sentences drawn from wikipedia selectively altered and then labeled with supported, refuted, or notenoughinfo									FALSE
207	2018	Thota, Aswini and Tilak, Priyanka and Ahluwalia, Simrat and Lohia, Nibrat	Fake news detection: a deep learning approach	SMU Data Science Review	articles	(A.i) article style and linguistic features	detection of language nuances	Fake News Challenge-1 dataset	80/20 train/test	(2.iii) CNN	(3.i) TF-IDF and Word2Vec embedding representations of article contents	mixed topics	accuracy of 94.21% on test data				FALSE
208	2020	Tian, Lin; Zhang, Xiuzhen; Wang, Yan; Liu, Huan	Early Detection of Rumours on Twitter via Stance Transfer Learning	Advances in Information Retrieval	claim	(U.i) 'user attitude distribution for twitter posts from their comments'	early detection of rumors when existing info is scarce	SemEval dataset	five-fold x validation	(2.iii) CNN						comparison to SVM, GRU-RNN, MT-ES, TD-RvNN	FALSE
209	2018	Tosik, Melanie; Mallia, Antonio; Gangopadhyay, Kedar	Debunking Fake News One Feature at a Time	arXiv:1808.02831 [cs]	articles (Fake News Challenge dataset)	(A.i) article body and title relationship (stance detection)	stance of title w.r.t body is a good first step in classification task	FNC-1 dataset	undisclosed	(2.ii) XGBoost	(3.i) headline and body length; cosine similarity		78.63% accuracy on fake news challenge tasks				FALSE
210	2018	Tschiatschek, S and Singla, A and Gomez Rodriguez, M and Merchant, A and Krause, A	Fake news detection in social networks via crowd signals	Companion of the web conference	articles; user behaviors	(U.ii) replies and shares	incorporating contextual signals into detection pipelines	from 154: 'Further, Tschiatschek et al leveraged crowd-sourcing solutions by processing users flagging and reporting of content			(3.ii) user comments and replies						FALSE
211	2020	Uppal, Anmol; Sachdeva, Vipul; Sharma, Seema	Fake news detection using discourse segment structure analysis	2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)	articles	(A.i) stylometry	detection of fake news articles from their structure	6398 data documents for training, 188 were reserved for testing on unseen data	see data cell	(2.iii) GRU	(3.i) article semantics	mixed U.S. news	74.62% accuracy on new data, with F1 score 0.76	n/a	n/a	n/a	FALSE
212	2018	Vo, Nguyen; Lee, Kyumin	The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake News	The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval - SIGIR '18	users (guardians); infrastructure (URLs)	(W.i) URL semantics; (N.i) sharing infrastructure	a recommendation model to personalize fact-checking URLs for users who spread fact-checking content	used Hoaxy system to identify fact-checking tweets and users from PolitiFact, Snopes, FactCheck.org, OpenSecrets.org, TruthOrfiction.com and Hoax-slayer.net. Dataset comprises 161,981 D-tweets and 69,396 S-tweets (58,821 retweets of D-tweets and 10,575 quotes of D-tweets) generated from May 16, 2016 to July 7, 2017	n/a	Optimization problem/matrix factorization	(3.i) URL semantics; (3.ii) co-occurrence of similar URLs within the same network	u.s. political news	GAU model has recall 0.20 ...? better than baselines but not great	n/a	n/a	comparison to Bayesian Personalized Ranking Matrix Factorization; generic matrix factorization; CoFactor; Collaborative Filtering Regression 	FALSE
213_e	2019	Volkova, Svitlana; Ayton, Ellyn; Arendt, Dustin L; Huang, Zhuanyi; Hutchinson, Brian	Explaining Multimodal Deceptive News Prediction Models	AAAI	posts (tweets)	(C.i) (A.i) combining text and image data to boost detection accuracy. detection of clickbait, propaganda, conspiracy, hoax, satire, disinfo	(C.i) image contents and degree of certainty in text contents	4.5M tweets in English retweeted from news accounts in 2016 similar to (Volkova et al. 2017); duplicate images removed	80/10/10 train/dev/test	(2.iii) NN	(3.i) images and text features. images are 2,048 vectors; text features include presence of punctuation, LIWC features, verse tenses and moods, degree of assertiveness	mixed news; political news	F1 0.738 for NN on lexical and image features	none described	none described	comparison to Adaboost performance	TRUE
214_e	2022	Wang, Ran; Du, Kehan; Chen, Qianhe; Zhao, Yifei; Tang, Mojie; Tao, Hongxi; Wang, Shipan; Li, Yiyao; Wang, Yong	RumorLens: Interactive Analysis and Validation of Suspected Rumors on Social Media	Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems	claims (tweets)	n/a; speed and volume of social media misinformation; proposes visualization tool to track spread of misinfo online	visualization tool; produces real-time view of tweet classifications (needless to say, is now defunct)	dataset of suspected rumors between 2019/12/27 and 2020/12/14 from the Sina Weibo Community Management center, with 936 suspected rumors, approximately 80000 corresponding retweets and comments, and 53843 user profiles.	n/a	n/a	(3.i) text embedding reps, including sentiment, topic; (3.iii) influence calculation, including engagement/followership	mixed news; Chinese political news	n/a	n/a	n/a		FALSE
216	2019	Wang, Yangqian; Han, Hao; Ding, Ye; Wang, Xuan; Liao, Qing	Learning Contextual Features with Multi-head Self-attention for Fake News Detection (2019)	Cognitive Computing – ICCC 2019	claims 	(U.i) source credibility; context	limitations to detection based on text contents alone	LIAR dataset	undisclosed	(2.iii) CNN	(3.ii) [in different sequences] credit history of speaker, context, speaker name, subject of statement, job title of speaker, home state of speaker, party affiliation of speaker	U.S. political news	45.3% on the full LIAR dataset	undisclosed training set; unclear distribution shift would be accommodated (or how this method would fare in the absence of context data)	none described	ablation analyses with Text-CNN only, Random, MMFD, Hybrid-CNN	FALSE
217	2015	Wu, Ke and Yang, Song and Zhu, Kenny Q	False rumors detection on Sina weibo by propagation structures	Proceedings of the 31st iEEE international conference on data engineering	claims (Weibo posts); 	(C.i); (N.i) early detection of rumors 	(N.i) propagation patterns; (A.ii) sentiment and topic	Sina Weibo posts	66/33 train/test; 10-fold x validation	(2.ii) hybrid SVM with graph kernel	(3.i) text embedding reps, including sentiment, emoji use; (3.iii) propagation/sharing	mixed news; Chinese political news	accuracy 0.904 and f1 0.886 with all features	none described	24 hours after the initial posting, the detection accuracy is 88%,' for early detection		TRUE
218	2017	Wu, L and Li, J and Hu, X and Liu, H	Gleaning wisdom from the past: early detection of emerging rumors in social media	Proceedings of the 2017 siam international conference on data mining	claims	(C.i) (N.i) using historical data to infer the presence of new rumors	(U.ii) 'personal involvement'; (A.ii) rumor topics	queries generated from 252 rumors from June 30th to July 11th, 9,918 tweets verified as rumors by two human annotators; checked against Snopes. final dataset contains 1,618 rumor instances and 8,300 non-rumor instances.	70 training ; test/validation undisclosed	(2.ii) SGD	authors refer in general terms to a feature selection process but don't disclose their own feature classes	mixed news; political news	CERT achieves 92.18% precision, 88.15% recall, 90.12% f score	none described	time lag' of 22 hrs for performance reported in table (92.18% precision)	compared CERT to SVM, Log-linear model, and RBF kernel	TRUE
220	2018	Wu, L and Rao, Y and Yu ,H and Wang, Y and Nazir, A	False information detection on social media via a hybrid deep model	International conference on social informatics	claims (weibo posts)	(C.i) semantics; (A.i) post sentiment ('misinfo associated with heightened emotion')	speed and volume of social media misinformation	LIAR; new Sina Weibo dataset comprising 40 thousand microblogs: 9600 true information, 8000 rumors, 8000 biases, 8000 fake news, and 8000 spams 	70/30 train/test	(2.ii), (2.iii) RCNN model to deeply capture to represent text semantics of information with context and design a model mixed with LSTM and ConvNet to learn text sentiment	(3.i) text topic and sentiment	mixed news; Chinese political news	0.433 accuracy, 0.749 recall, 0.549 f1 on Weibo dataset	none described	none described	compared to LIAR dataset	TRUE
221	2012	Yang, Fan; Liu, Yang; Yu, Xiaohui; Yang, Min	Automatic detection of rumor on Sina Weibo	Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics - MDS '12	claims (weibo posts)	(A.ii) topic; (N.ii) propagation (likes and reshares); (W.iv) user location 	speed and volume of social media misinformation; linguistic traits of Chinese vs English	confirmed false rumors from Sina Weibo community center	10 fold x-validation	(2.ii) SVM	19 features are extracted from each microblog, including (3.i) the content,  (3.ii) the number of replies and retweets; (3.iii) the user account; (3.iv) the micro-blogging client program used, the location 	Chinese news rumors	achieves accuracy of 78.0066%, 77.3574%, and 78.6617% on content-based, account-based, and propagation-based features only	none described	none described	none described	TRUE
222	2019	Yang, Shuo; Shu, Kai; Wang, Suhang; Gu, Renjie; Wu, Fan; Liu, Huan	Unsupervised Fake News Detection on Social Media: A Generative Approach	AAAI	claims (tweets); infrastructure; user behaviors	(A.ii) topic; (N.ii) propagation (likes and reshares)	extract users’ opinions on the news by exploiting the auxiliary information of the users’ engagements with the news tweets on social media, and aggregate their opinions in a well-designed unsupervised way'	LIAR, Buzzfeed News	undisclosed	(2.iii) PGM	(3.ii) number of replies and retweets; (3.iii) verified status of user account. user sensitivity and specificity: probability that the user j thinks a news piece is real given the truth estimation of the news is true and fake, respectively 	news rumor topics found in LIAR and Buzzfeed News datasets	UFD achieves accuracy overall of 0.759; on true news, attains 0.766 precision, 0.783 recall, 0.774 f1; on false news, attains 0.750 precision, 0.732 recall, 0.741 f1	none described	none described	Majority Votin; TruthFinder; CRH; LTM; SVM	TRUE
223	2018	Yang, Yang; Zheng, Lei; Zhang, Jiawei; Cui, Qingcai; Li, Zhoujun; Yu, Philip S.	TI-CNN: Convolutional Neural Networks for Fake News Detection	arXiv:1806.00749 [cs]	articles; images	(A.i) article semantics with image contents	incorporation of image data into social media post classificatoin	20,015 news, i.e., 11,941 fake news and 8,074 real news	80/10/10 train/tune/test	(2.iii) CNN	(3.i) presence of punctuation; number of words and sentences; lexical diversity; sentiment	undisclosed	0.9220 precision, 0.9277 recall,  0.9210 f1	none described	none described	none described	TRUE
224_e	2023	Yang, Yunkang; Davis, Trevor; Hindman, Matthew	Visual Misinformation on Facebook	Journal of communication	claims (facebook)	(C.i) prevalence of visual misinformation on facebook	incorporation of image data into social media post classificatoin	13,284,364 image posts shared across 14,532 US public pages and 11,454 US public groups, which is estimated to contain at least 94 percent of US politics image post interactions	n/a	perceptual hash matching for image comparison	(3.i) image contents; authors label any images critical of one party as being aligned with the opposing party	U.S. political news	In the 1000 image post random sample, we found 516 right leaning image posts and 413 left leaning posts. About 39% of right leaning image posts contained elements of misinformation whereas the number is only 5% on the left.'	none described	authors state their confidence in the robustness of their results, given depth of their coverage in the sample image set	authors cite works that use URLs to infer prevalence of misinfo; these links put the %age of misinfo on FB at around 15%	FALSE
225	2014	Yang, Zhi and Wilson, Christo and Wang, Xiao and Gao, Tingting and Zhao, Ben Y and Dai, Yafei	Uncovering social network sybils in the wild	ACM Transactions on knowledge discovery from data	users	(N.ii) social graph topologies	updated mechanisms for detecting Sybils on social networks	more than 560K Sybil accounts on Renren, a Chinese social network. manually labeled dataset of 1K accounts	80/20 train/test	(2.ii) SVM	(3.ii) frequency of friend requests sent, accepted, and received	n/a	99% of Sybils in test set detected	yes (method is in production at Renren)	yes (method is in production at Renren)	none described	TRUE
226	2017	Yu, F and Liu, Q and Wu, S and Wang, L and Tan, T et al	A convolutional approach for misinformation identification	Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence	claims (tweet, blog post); event (collection of posts)	(N.ii), (A.ii) identification of rumoring 'event' (defined as a series of 'correlative microblog posts')	supervised methods fail to extract 'higher-level interactions'	Weibo dataset (Castillo 2011); Twitter16 (Ma 2016)	10% for tuning; 67.5/22.5 train/test	(2.iii) CNN	(3.i) undisclosed semantic text features; authors visualize key features and conclude that 'forepart of input usually obtains relatively stronger response than the rear part' 	mixed rumors; Chinese political news	CAMI achieves accuracy 0.933 on Weibo and 0.78 on Twitter; precision 0.92 on Weibo misinfo, 0.92 recall on true Weibo info; and 0.93 F1 on Weibo true and false info. 0.744/0.82 precision on false/true twitter info; 0.793 F1 on false twitter info	none described	none described	comparison to SVM, DT-Rank	FALSE
228	2016	Zeng, Li; Starbird, Kate; Spiro, Emma	#Unconfirmed: Classifying Rumor Stance in Crisis-Related Social Media Messages	AAAI	claims (tweets)	(A.ii) stance on rumoring topics	rumor detection during crisis events	 4,300 manually coded tweets relating to the Sydney hostage crisis ('Sydney siege'); five rumors relating to the Sydney siege, named as 'Flag,' 'Airspace,' 'Suicide,' 'Hadley,' 'Lakemba,' respectively)	10-fold x validation; sampling for pooled rumors sets proportional to representation of each rumor in the full dataset; training splits undisclosed	(2.ii) LR, NB, RF	(3.i) feature importance analysis discloses top ten lexical features; all have weights < 0.07. Top feature is negation word 'NOT,' followed by 'not isis'	Sydney siege and five related rumors	RF achieves accuracy and F1 above 0.85 on all tasks	none described	none described	none described	FALSE
229	2019	Zhang, Chaowei; Gupta, Ashish; Kauten, Christian; Deokar, Amit V.; Qin, Xiao	Detecting Fake News for Reducing Misinformation Risks Using Analytics Approaches	European Journal of Operational Research	article	(A.i) sentiment and syntax analysis		CNN and NYT provided real news data; fake news from list of websites (includes naturalnews.com, greenvillegazette.com, advocate.com)	clustering of news around topics; similarity comparison of news to existing clusters, identification of outliers; topics as proxies for factuality	(2.ii) KNN	some		92.49% classification accuracy and 94.16% recall	a majority of news articles are time sensitive, implying that better fake-news detection may be handled in real-time. to deal with real-time news,models need to incorporate a pre-processing module to process real-time properties of news articles. the development of such real-time pre-processing module is beyond hte curent scope of this study but is an interesting topic for future research'	propose clustering as a way to speed up checking on networks	unspecified	FALSE
230_f	2016	Zhang, H and Alim, MA and Li, X and Thai, MT and Nguyen, HT	Misinformation in online social networks: detect them all with a limited budget	ACM Trans Inf Syst	users; networks	(N.ii) social graph topologies	placement of 'monitor' nodes who can detect misinfo source spread?	Twitter, Epinion, Slashdot data; resp. 88,484 / 75,879 / 77,360 nodes and 2,364,322 / 508,837 / 905,468 edges	not described	(2.iv) min-cut set algorithm	(3.ii) edge transmission probability (uniform random assignment); social graph topology	U.S. political news	no detection statistics given, but authors show that MMSC employs fewer monitor nodes to achieve same effects as baselines	none described	none described	comparison to degree-centrality, random selection	TRUE
231	2018	Zhang, H and Kuhnle, A and Smith, JD and Thai, MT	Fight under uncertainty: restraining misinformation and pushing out the truth	IEEE/ACM international conference on advances in social networks analysis and mining	users; networks	(N.ii) social graph topologies	countering misinfo with dissemination of correct info	BlogCatalog, Epinions, Livemocha, Livejournal; resp. 10K, 76K, 104K, and 2M nodes and 334K, 509K, 2M, and 15M edges. 	not described	(2.iv) min-cut set algorithm	(3.ii) edge transmission probability (uniform random assignment); social graph topology	mixed topic	no detection statistics given, but authors show that MMSC employs fewer monitor nodes to achieve same effects as baselines	none described	no testing on live feeds, though authors do disclose runtimes for their algorithm	comparison to Random degree, high degree, PageRank, and Greedy	FALSE
232	2018	Zhang, Jiawei; Cui, Limeng; Fu, Yanjie; Gouza, Fisher B.	FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural Network 	arXiv:1805.08751 [cs, stat]	articles; users; topics	networks											FALSE
233	2019	Zhang, Q and Lipani, A and Liang, S and Yilmaz, E	Reply-aided detection of misinformation via bayesian deep learning	The world wide web conference	claims; context	(C.i) claim semantics; (U.i) user responses to claim	uncertainty / confidence scores should accompany single labels of truth/falsity	RumourEval and PHEME	reported for each dataset; see Table 1	(2.iii) Bayesian deep learning model	(3.i) neural model to extract text features from claims; (3.ii) user replies represented by LSTM after ranking in chron. order	mixed topic	accuracy 80.95%, F1 77.78% on RumourEval and 80.33% acc and 78.78% F1 on PHEME	none described	none described	comparison to SVM, CNN, TE, DeClarE, Multitask, TRNN	FALSE
239	2019	Zhou, Xinyi; Jain, Atishay; Phoha, Vir V.; Zafarani, Reza	Fake News Early Detection: A Theory-driven Model	arXiv:1904.11679 [cs]	articles				early detection								FALSE
240	2018	Zhou, Xinyi; Zafarani, Reza	Fake News: A Survey of Research, Detection Methods, and Opportunities	arXiv:1812.00315 [cs]	article	semantics; networks	survey	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	FALSE
241_f	2019	Zhou, Xinyi; Zafarani, Reza	Network-based Fake News Detection: A Pattern-driven Approach	SIGKDD Explorations Newsletter	users; networks	(N.ii) social graph topologies	authors state that propagation-based detection techniques have been underexplored	FakeNewsNet dataset	5-fold x validation; authors avoid leakage by using historical information rather than whole dataset	(2.ii) SVM, KNN, NB, DT, RF	(3.ii) user engagement; counts of spreaders	U.S. political news	achieves 0.929 accuracy and 0.932 F1 on Politifact; 0.835 accuracy and 0.842 F1 on BuzzFeed	none described	none described	compared to news content detection approaches, with word Word2Vec embeddings and Doc2Vec document embeddings	TRUE
242	2020	Zhou, Yue; Zhang, Yan; Yao, JingTao	Satirical News Detection with Semantic Feature Extraction and Game-theoretic Rough Sets	Foundations of Intelligent Systems	claims (tweets)	(A.i) presence or absence of satire style cues	(A.i) semantic features of satire	9,000 news tweets from satirical news sources such as The Onion and Borowitz Report and about 11,000 news tweets from legitimate new sources such as Wall Street Journal and CNN Breaking News over the past three years'	splits undisclosed: 'We perform extensive experiments on the collected dataset, fine-tuning the model by different discretization methods and variation of equivalent classes.'	Game-theoretic Rough Set (GTRS) model for determining thresholds for categorization 	(3.i) TF-IDF for word-level representations; inconsistencies between noun-verb phrases, clauses, and entities and noun phrases	satirical U.S. political news	82.71% accuracy; 97.49% coverage; 81.89% modified accuracy	none described	none described	comparison to SVM, Pawlak rough set model	FALSE
245	2015	Xiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui Fang, Sameena Shah∗	Real-time rumor debunking on Twitter	CIKM '15	networks (tweets)	(N.i) real-time rumor debunking on user traits and contents	(A.i) are contents rumor-like?; (N.i) viral reshares?; (U.i) credible accounts?	Authors crawled snopes.com and emergent.info; collected 2,299 stories posted until March 2015; eliminated stories that were either not ‘newsworthy’ or that did not have an explicit confirmation of veracity. The resulting dataset comprises 94 true and 446 false stories.	10-fold x validation	(2.ii) SVM, decision trees, decision rules, and Bayes networks	adapted from feature classes described in Castillo 2011 and Yang 2011; includes (3.i) message-level features, such as length, sentiment, count of exclam. points; (3.ii) user features, such as verif status, follower count, age. also event-level and propagation-based features, which are a mix of semantic and (3.iii) network-based features: counts of reshares, relevant tweets	rumoring events; U.S. news	0.78, 0.857, and 0.897 accuracy on 5, 100, and 400 tweets resp.; 0.795, 0.834, and 0.875 accuracy 1hr, 12hrs, and 72hrs after the fact	none described	compare performance to human checking speeds based on retrospective reports logged on snopes and emergent. authors disclaim that they're limited by the fact that their method detects news links (so the time lag is at least as great as the amount of time required for news outlets to publish)	all models and feature sets adapted from existing work, including Castillo 2011, Yang 2011, and Qazvinian 2011	FALSE
246	2019	Chunyuan Yuan, Qianwen Ma, Wei Zhou, Jizhong Han, Songlin Hu.  	Jointly embedding the local and global relations of heterogeneous graph for rumor detection.	In 19th IEEE International Conference on Data Mining, IEEE ICDM 2019.	networks (events)	(N.i), (C.i) ''integrat[ing] global structural and local semantic information based on the heterogeneous network for detecting rumors'	(C.i) tweet, reply, and retweet contents; (N.i) sharing behaviors	Weibo, Twitter15, Twitter16	10% instances as the development data set, and split the rest for training and testing set with a ratio of 3:1	(2.iii) global-local attention network (GLAN)	non-specific; (3.i) attention representation of tweets and replies; (3.iii) 'global heterogeneous network' 	U.S. and Chinese news	accuracy of 94.6% on Weibo data set and 90.5%, 90.2% on two Twitter data sets	none described	compare performance to 'real time' by making subset of tweets available on a delay (not a real live content feed)	compared to DTC, SVM, GRU	FALSE
247_f	2020	Baly, Ramy and Karadzhov, Georgi and An, Jisun and Kwak, Haewoon and Dinkov, Yoan and Ali, Ahmed and Glass, James and Nakov, Preslav	What Was Written vs. Who Read It: News Media Profiling Using Text Analysis	ACL 2020	websites	(A.ii) topic/stance	inferring factuality of whole news sites from text content features	MediaBias/FactCheck dataset, comprising list of news media along with labels of political bias and factuality of reporting. Wikipedia pages and twitter profiles for these sites	five-fold x validation	(2.ii) SVM	(3.i) BERT embeddings for topic, content; (3.iii) twitter, youtube, facebook followership	U.S. political news	71.52 accuracy and 67.25 macro F1 on article- and user-based features for factuality prediction	none described	none described	none described	TRUE
248 	2019	Georgios Gravanis, Athena Vakali, Konstantinos Diamantaras, Panagiotis Karadais	Behind the cues: a benchmarking study for fake news detection		articles		benchmarks of misinfo detection methods										
252	2020	Wilson et al.	Social media and vaccine hesitancy 	BMJ	claims; articles	(C.i) tweet semantics 	COVID; anti-vax rumors	geocoded tweets from 2018-2019 (2.5b in total); 259K of these addressed vaccine misinfo		n/a	(3.i) sentiment classification (pos, neg, neut) and presence of language indicating intention to conduct offline activities; presence of foreign disinformation		authors identify causal relationship between public confidence in vaccination and foreign disinformation campaigns (a correlation exists, but you couldn't say much more)	n/a			FALSE
253	2020	Yang et al.	Scalable and generalizable social bot detection through data selection	AAAI 	users, networks	(U.ii) users, networks	speed and volume of misinfo on social media platforms	Twitter data set; user metadata only (less performant but easier to obtain); only 20 features; AUC sometimes worse than 0.50, indicating directly contradictory labels		trained on merged and split data sets intended to improve generalizability (e.g., celebrity, pronbots, botometer-feedback and political-bots, vendor-purchased and verified)	5/11 data sets indicated clear separability between bots and human accounts; a data set labeled according to timing of account had poor separability.		authors do attempt realtime classification using Firehose; they report classifier speed but not performance(?); maybe an obvious result that tuning input data set and validation data set will have a direct impact on classifier performance	at best 0.84-0.87 AUC on certain data sets			FALSE
254	2020	Keller et al.	Political Astroturfing on Twitter: How to Coordinate a Disinformation Campaign	Political Communication	networks	(N.ii) astroturfing	South Korean National Information Service’s (NIS) disinformation campaign	Twitter data set; distinguishes between fully automated bots, human actors, and 'cyborgs'; korean language dataset contains 75 m tweets and 702 of 1008 known NIS accounts	n/a	(2.iv) manual checking of co-tweet networks	(3.iii) user-user interactions; timing of tweets (during the day, whereas normal accounts tweet after hours)	astroturfing related to Korean political news	surfaced 921 additional potential astroturfing accounts	n/a	distinguishes between intrinsic qualities of account that identify it as bot-like and coordinated activity (reasoning being that the latter is more immune to distinctions between fully-human, cyborg, and fully-automated campaigns)	n/a	FALSE
255	2019	Milajerdi et al.	HOLMES: Real-time APT Detection through Correlation of Suspicious Information Flows	IEEE S&P	networks	(N.ii) APTs	real-time APT detection	toolbox' of several hundred low-level actions that might be understood as potentially malicious behavior in the context of larger information flows ('TTP specifications provide the mapping between low-level audit events and high-level APT steps). 		n/a	(3.ii) TTPs (tactics, techniques, and procedures), comprising 200 behavioral patterns -- "each TTP defines one possible way to realize a particular high-level capability"; these are abstracted to a 'provenance graph' that identify possibly harmful information flows that hide behind benign system processes		real-time and adversarial experimental settings; some false positives in the former. latter was a red- and blue-team adversarial setup coordinated by DARPA	no observed FNs in real-time tests; far more FPs 			FALSE
256	2011	Ratkiewicz et al.	Detecting and Tracking Political Abuse in Social Media	AAAI	networks	(N.ii) networks 	spam detection systems often focus on the content of a potential spam message ... in detecting political astroturf, we focus on how the message is delivered rather than on its content'. Klatsch identifies specific rumoring topic, then analyzes the user/tweet network for the following features: nodes, edges, mean degree, mean strength, maximum in/out degree, user with max in/out degree 	astroturfing in particular; tweets in particular (600K, filtered for relevance to political topics); hand-annotated memes (61 'truthy' memes and 305 'legitimate' memes)	10-fold x validation	(2.ii) SVM, Adaboost	(3.ii) the topology of the diffusion networks, (3.i) sentiment analysis, and crowdsourced annotations'; 31 features for each meme for training classifiers		better than 96% accuracy; authors do report real-time performance 		authors note that the kind of content- and account-based classification approach that is applied to spam detection often fails here, as astroturfers attempt to loop regular users into the diffusion network; authors also note that sampling tweets provides suboptimal understanding of underlying network characteristics (citing leskovec and faloutsos 2006)		FALSE
257_s	2020	Wu et al. 	Misinformation in Social Media: Definition, Manipulation, and Detection	ACM SIGKDD	n/a	[survey]		[survey] 	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	FALSE
258	2009	Stone-Gross et al. 	Your botnet is my botnet: analysis of a botnet takeover	ACM CCS '09	networks; users	(N.ii) botnets		Torpig bots constituting a botnet; authors point out the problem that 'the detection is limited to those botnets that actually exhibit the activity targeted by the analysis'		the use of domain flux in botnets has important consequences in the arms race between botmasters and defenders'	authors propose infiltration as an alternative to passive observation of botnet activity	n/a	n/a	n/a	n/a		FALSE
259	2008	Yu et al.	SybilLimit: A Near-Optimal Social Network Defense against Sybil Attacks	IEEE S&P '08	users; networks	sybils	\'the negative results in Douceur's initial paper on Sybil attacks showed that sybil attacks cannot be prevented unless special assumptions are made.'	\'the negative results in Douceur's initial paper on Sybil attacks showed that sybil attacks cannot be prevented unless special assumptions are made.'		(2.iv) random walk	(3.ii) user-user interactions represented by a social graph	n/a	Compared to SybilGuard that accepted O( √ n log n) sybil nodes per attack edge, SybilLimit accepts only O(log n) sybil nodes per attack edge.	n/a	n/a	comparison to SybilGuard, SybilInfer	FALSE
260	2005	Christodorescu et al.	Semantics-aware malware detection	IEEE S&P '05	n/a	(C.i) code semantics	detection of malware from code semantics 	begins with known 'vocabulary' of code attacks (worms, trojans, etc) and 'mutates' templatized attack patterns to account for changes in these semantics over time 		regex detection							FALSE
261	2010	Grier et al. 	@spam: the underground on 140 characters or less	ACM CCS '10	articles; claims	(C.i) post and (U.i) account semantics	detection of spam and inference of spamming account characteristics			(2.iv) clustering on social graphs	(3.i) appearance of mentions (@), retweets (RT), and hashtags (#); (3.iii) account metadata semantics; (3.ii) clickthrough on spammy links	mixed commercials/ads/gambling/realty	use of hashtags (ρ = .74) and retweets with hashtags (ρ = .55) is correlated with higher clickthrough rates	none described	none described	none described	FALSE
262	2012	Cao et al.	Aiding the Detection of Fake Accounts in Large Scale Social Online Services	USENIX NSDI '12	users	(U.ii) user account interactions 	speed and volume of misinfo on social networks	non-Sybil regions are sampled from real social networks, e.g. Facebook and Barabasi's scale-free model	n/a	(2.iv) random walk; trust propagation 	(3.ii) user-user interactions represented by a social graph	n/a	∼90% of the 200K accounts that SybilRank designated as most likely to be fake, actually warranted suspension. 'We observe that due to the high FPs of binary Sybil/non-Sybil classifiers, manual inspection needs to be part of the decision process for suspending an account. Consequently, our aim is to efficiently derive a quality ranking, in which a substantial portion of Sybils ranks low.'	none described	none described	comparison to SybilLimit, SybilInfer	FALSE
263	2010	Gao et al.	Detecting and characterizing social spam campaigns	ACM SIGCOMM	networks	(N.ii) coordinated spam account interactions	detection of large-scale coordination on social media platforms	wall messages received by roughly 3.5 million Facebook users (more than 187 million messages in all)		(2.iv) clustering on social graphs	(3.ii) temporal records of interactions (to detect 'burstiness') ; unique user identifiers; (3.iv) spam url semantics	n/a	system detected roughly 200,000 malicious wall posts with embedded URLs, originating from more than 57,000 user accounts.	none described	none described	none described	FALSE
264	2020	Cresci	A decade of social bot detection	ACM Communications	users; networks	bots	n/a	[popular writing/review in ACM communications]	n/a	'Future efforts should focus on measuring the extent of inauthentic coordination rather than on trying to classify the nature of individual accounts'; 'we observe that both the individual and the group-based approaches to social bot detection follow a reactive schema'	n/a	n/a	only 5% of newer bots are removed from social platforms, whereas older ones are removed 60% of the times. Moreover, hundreds of tech-savvy social media users that participated in a crwod-sourcing experiment were able to tell apart newer bots from legitimate users only 24% of the times. The same users were instead able of spotting older bots 91% of the time'; 'newer bots are more similar to legitimate human-operated accounts than to other older bots'	n/a	n/a	n/a	FALSE
265	2011	Thomas et al. 	Design and Evaluation of a Real-Time URL Spam Filtering Service	IEEE S&P '11	websites	(W.i) domain semantics	real-time spam filtering	email and tweet spam corpora: URLs captured by spam traps operated by major email providers, blacklisted URLs appearing on Twitter, and non-spam URLs appearing on Twitter that are used to represent a non-spam data sample. 	5-fold x validation	(2.ii) LR	(3.iv) URL semantics; JS features; http header tokens; etc	mixed spam topics	94.15% accuracy, 1.81% FP, 22.11% FN with tweet features	n/a	conducted in real-time; latency approximately 3 seconds, training time is 45 mins	authors disclaim that ground truth is difficult to resolve for these datasets	TRUE
266	2019	Zannettou et al.	Disinformation Warfare: Understanding State-Sponsored Trolls on Twitter and Their Influence on the Web	ACM WWW	networks; users	(U.i), user account metadata semantics	identifying foreign influence operations	27K tweets posted by 1K Twitter users identified as having ties with Russia’s Internet Research Agency; list compiled by U.S. Congress	n/a	Hawkes Processes to model troll influence in different online communities	(3.i) language used by accounts; (3.iii) location and account characteristics; (3.iv) client used for tweets	mixed topics	not a classification result	n/a	not generalizable to unknown trolling behaviors	n/a	FALSE
267	2020	Rauchfleisch, Kaiser	The False positive problem of automatic bot detection in social science research	PLoSOne	networks; users	(C.i) post semantics; (U.ii) network activity	evaluation of generalizability and accuracy of Botometer scores	Tweets; all official twitter accts belonging to members of German Parliament (n=532), members of U.S Congress (n=516), list of known bots (n=935); manually annotated set of human and bot accounts from Botometer creators		(2.iii) only works well in cases where there is a clear-cut distinction between bots and human accounts, resorts to chars of accts that mark them as bot or not (e.g., bio says its a bot, presence of blue checkmark)	unsupervised model; Botometer features are a black box	mixed topics	Botometer precision on tweet datasets, including non-English languages; re-evaluation in new contexts, on non-English data sets, showed significant performance degradation	n/a	n/a	n/a	FALSE
268	2009	Danezis and Mittal	SybilInfer: Detecting Sybil Nodes using Social Networks	NDSS '09	users	(U.ii) account activity	accurately distinguishing between honest and dishonest nodes in social graph	synthetic social network topology for experimental evaluation	n/a	(2.iv) Bayesian inference; random walk on social graph 	cut size between dishonest/honest nodes	n/a	on a synthetic topology, achieves FP rate less than 5%	n/a	n/a	n/a	FALSE
269	2006	King et al.	SubVirt: implementing malware with virtual machines	IEEE S&P '06	n/a	(malware)	not a classification paper; discusses VMBR detection though.	 VMBRs are fundamentally more difficult to detect than traditional malware because they virtualize the state seen by the target system and because an ideal VMBR modifies no state inside the target system.'	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	FALSE
270	2013	Wang et al. 	You Are How You Click: Clickstream Analysis for Sybil Detection	USENIX '13	users	(U.i) clickstream profile per user	CAPTCHAs and graph-based Sybil detectors not sufficiently effective	ground-truth traces of 16,000 real and Sybil users from Renren	10-fold x validation	(2.ii) SVM	(3.iii) friending, photo uploads, (3.ii) profile appearance, posts, blogs	n/a	FP rate less than 1%	n/a	n/a	n/a	TRUE
271	2010	Whittaker et al.	Large-Scale Automatic Classification of Phishing Pages	NDSS '10	websites	(W.i), URL semantics	detection of fraudulent websites	classifier analyzes millions of pages a day'	undisclosed	(2.ii) LR	(3.iv) URL semantics	n/a	false positive rate below 0.1%.	n/a	n/a	n/a	FALSE
272	2019	Zannettou et al.	Who Let The Trolls Out?: Towards Understanding State-Sponsored Trolls	ACM WebSci	users; networks	(W.i), (U.i) URL semantics shared by users	identification of state-sponsored influence operations online	10M posts by 5.5K Twitter and Reddit users identified as Russian and Iranian state-sponsored trolls	undisclosed	Hawkes Processes to model troll influence in different online communities	(3.iii) time of account creation; post timing; followership (3.ii) language; (3.i) tweet contents and hashtag usage		authors show that Russian trolls were more efficient and influential in spreading URLs on other Web communities than Iranian trolls	n/a	n/a	n/a	FALSE
273	2021	Pacheco et al.	Uncovering Coordinated Networks on Social Media: Methods and Case Studies	AAAI '21	networks	(N.ii) campaigns	survey of existing methods and datasets for network detection on social media	Twitter; hashtags, bio elements, usernames	undisclosed	trains on subsets of tweets with shared hashtags, implicated accounts, co-retweets	five case studies: 1) account handle sharing, 2) image coordination, 3) hashtag sequences, 4) co-retweets, and 5) synchronized actions. it is possible to engineer feature sets from combinations of 'traces.' Traces are 'atomic' properties of tweets that belong to one of four categories: content, activity, identity, and combination. Makes important point that best way to reduce number of false positives is to 'engineer features that are suspicious by construction': in this case, account handle sharing and identical sequences of hashtags		survey of results	n/a	n/a	n/a	FALSE
274	2014	Wang et al.	Man vs. Machine: Practical Adversarial Detection of Malicious Crowdsourcing Workers	USENIX '14	users	(U.i) user account features	attackers can modify ML model behavior by poisoning their training data	Sina Weibo accounts	50/50 train/test	(2.ii) SVMs, Bayesian, Decision Trees and Random Forests.	(3.iii) profile features; (3.ii) user interactions; tweeting clients; temporal behavior	mixed topic	robustness to adversarial attacks and fitting accuracy frequently at odds; more accurate fits (especially to smaller, homogeneous populations) make models more vulnerable to deviations introduced by adversaries; thorough evaluation of performance under adversarial attacks and training data poisoning attacks	n/a	n/a	n/a	FALSE
275	2019	Lukito	Coordinating a Multi-Platform Disinformation Campaign: Internet Research Agency Activity on Three U.S. Social Media Platforms, 2015 to 2017	Political Communication	networks	(U.ii) user activity on Twitter, Facebook, Reddit	Russian IO from 2015-2017 in the U.S.	activity data (tallies of actions only, no content or audience interaction data) from known IRA accounts on Twitter, Facebook, and Reddit; these statistics were self-reported by each platform(!!!!)	undisclosed	time series analysis to determine directionality of IRA activity and information spread	(3.iii) posts made, comments made, retweets. FB analysis considered ad deployment	mixed topic	IRA activity on Twitter appeared to be Granger-caused by IRA activity on Reddit, but not vice versa (seems possible that the IRA was testing prototype messages on Reddit prior to posting on Twitter)	n/a	n/a	n/a	FALSE
276	2019	Reis et al.	Explainable Machine Learning for Fake News Detection	WebSci '19	articles	exhaustive: (C.i); (N.i); (U.i) 	discriminatory power of features used in supervised models is poorly understood	Buzzfeed news data set 'enhanced with facebook commentaries on labeled news stories'	undisclosed	exhaustive testing of common models	survey of existing methods yielded a set of almost 200 features : lexical and syntactic features; moral foundation cues; network structure; temporal patterns; bias cues, ...	mixed topic	mean AUC is in the range [0.855, 0.885]	only 2.2% of the models achieve a detection performance higher than 0.85 in terms of the area under the ROC curve (or simply, AUC)	n/a	n/a	FALSE
277_f	2020	Alizadeh et al.	Content-based features predict social media influence operations	Science Advances	networks	(C.i), (A.i) content features	distinguishing troll activity from organic social media activity	publicly available Twitter data on Chinese, Russian, and Venezuelan troll activity targeting the United States, as well as the Reddit dataset of Russian influence efforts	undisclosed	(2.ii) RF	(3.i), (3.iv) post-URL pair: timing, word count, URL domain reputation	mixed topic	macro-F1 of 0.99 on Twitter data in Venezuela	n/a	n/a	n/a	FALSE
278	2021	Nizzoli et al.	Coordinated Behavior on Social Media in 2019 UK General Election	AAAI '21	networks	campaigns	most IO investigations are heavily manual	tweets collected via twitter API; tweets collected one month in advance of GE in britain in 2019; 	undisclosed	(2.iv) iterative clustering and community detection with a moving similarity threshold	(3.iii) user-user similarity, as measured by cosine distance between embedding vectors	2019 UK general election	Conservatives were overall more coordinated than Labours and that they also featured a higher degree of automation and Twitter suspension	n/a	n/a	n/a	FALSE
279	2022	Saeed et al.	TROLLMAGNIFIER: Detecting State-Sponsored Troll Accounts on Reddit	IEEE S&P '23	user	(U.ii) user interactions on social media platforms	detection of state-sponsored influence operations	known troll Reddit accounts curated manually	10-fold x validation	(2.ii) RF, KNN, SVM, DT	(3.iii) commenting and other activity on threads started by known troll accounts	mixed topic	66% of detected accounts show signs of being instrumented by malicious actors	n/a	not possible to detect behaviors not represented in training set	n/a	TRUE
280	2017	Varol et al.	Early detection of promoted campaigns on social media	EPJ	networks	(N.ii) user-user interactions	early detection of influence operations	authors crawled Twitter webpage at regular intervals of 10 minutes to collect all organic and promoted hashtags trending in the United States between January and April 2013, for a total of  927 hashtags	10-fold x validation	(2.ii) KNN	(3.iii) network and diffusion patterns, timing signals, (3.i) content and sentiment information, and (3.ii) user meta-data	mixed topic	75% AUC score for early detection, increasing to above 95% after trending.	n/a	n/a	n/a	TRUE
281	2021	Sharma et al.	Identifying Coordinated Accounts on Social Media through Hidden Influence and Group Behaviours	ACM SIGKDD	networks	(N.ii) user-user interactions	state-sponsored misinfo campaigns on social media	real-world social network data collected from Twitter related to coordinated campaigns from Russia’s Internet Research Agency targeting the 2016 U.S. Presidential Elections, and to identify coordinated campaigns related to the COVID-19 pandemic	75/15/10 train/validation/test 	(2.iii) generative model, AMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group Estimation)	(3.iii) network and diffusion patterns, timing signals	as described in dataset	AMDN-HAGE-KNN achieves AUC better than 0.95 	n/a	n/a	n/a	TRUE
282	2012	Chu et al. 	Detecting social spam campaigns on Twitter	ACNS	networks	(C.i) spam	shifting from individual to collective detection	 50 million tweets posted by 22 million users.	10-fold x validation	(2.ii) RF, DT, KStar, BN, LR	(3.iii) timing entropy; active time; (3.ii) tweet number; (3.i) content self-similarity; spam word ratio	mixed topic	all models achieve accuracy better than 82%	n/a	n/a	n/a	FALSE
284	2020	Vargas et al.	On the Detection of Disinformation Campaign Activity with Network Analysis 	ACM CCSW	networks	(N.ii) co-tweeting activities	difficult to distinguish between inauthentic and authentic coordination (i.e., coordination doesn't necessarily imply inauthenticity)	authors collected the activity of accounts from the members of the United States Congress as well as the United Kingdom’s Members of Parliament (MPs)	time-progressed training and last-day testing to avoid temporal leakage	(2.ii) RF	(3.iii) co-tweets, co-mentions, co-url, co-retweets	U.S. and U.K. political news	on in-distribution data, F1 = 0.98	see next cell	F1 = 0.71 on out-of-distribution data	n/a	FALSE
285	2019	Yuan et al. 	Detecting Fake Accounts in Online Social Networks at the Time of Registrations	ACM CCS '19	users	(U.i) time of account registration w.r.t other users	content- and behavior-driven methods operate on a significant delay	verified on 400K per million new registered accounts each day; can achieve a precision of over 96% on average	undisclosed	(2.iv) graph inference 	(3.iii) account registration patterns/timing; IP; nickname; WeChat version; hashed device ID; phone number	n/a	Precision 92.4%, Recall 80.2%, and F-Score 85.9% on a test dataset	n/a	n/a	n/a	FALSE
286	2022	Magelinski et al.	A Synchronized Action Framework for Detection of Coordination on Social Media	JOTS	networks	(U.i) shared hashtags and other coordinated activities	successful generalized coordination detection might reinforce existing biases	Twitter dataset collected around the Reopen America Protests of 2020.	undisclosed	(2.iv) clustering on social graphs	(3.iii) user-user interactions, represented by a social graph; (3.i) presence of hashtags	Reopen America 	does not present classification results	n/a	n/a	n/a	FALSE
287	2017	Nilizadeh et al.	POISED: Spotting Twitter Spam Off the Beaten Paths	ACM CCS '17	claims (tweets)	(N.ii) propagation patterns	Spam and other malicious content, on the other hand, follow different spreading patterns than innocuous content	1.3M tweets collected from 64K users	{3, 5, 10}-fold x validation	(2.iv) clustering on social graphs	(3.iii) user-user interactions, represented by a social graph; (3.i) topic of tweets	mixed topic	91% precision and 93% recall	n/a	n/a	compared to SVM, RF, NB	FALSE
288	2010	Pitsillidis et al. 	Botnet Judo: Fighting Spam with Itself	NDSS '10	networks	(N.ii) bots		email spam corpus; spam botnets that launder spam messages through multiple mail servers / addresses	training on 1000 spam emails and evaluation on 4000 spam emails	regex/template detection	(3.i) infers polymorphic email template used to generate spam emails: 'form letters ... consisting of text interspersed with substitution macros that are instantiated differently in each generated message'	n/a	three different experiments: 1) testing on spam generated synthetically from actual templates used by the Storm botnet; 2) actual spam sent by four different bots; 3) real deployment scenario, training and testing on different instances of the same bot; specificity equals safety,' generalizability not necessarily good or desirable; FPR should be extremely low (99% of templates had FNR of 0.22% or lower); real time test setting was good too; templatized detection worked because testing/use case was extremely specific	n/a	n/a	n/a	FALSE
290	2023	Mirza et al.	Tactics, Threats & Targets: Modeling Disinformation and its Mitigation	NDSS '23	users	n/a	survey study of challenges for human fact-checkers and transferrable lessons from security research	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	FALSE
291_f	2023	Paudel et al.	LAMBRETTA: Learning to Rank for Twitter Soft Moderation	IEEE S&P '23	claims (tweets)	(C.i) post semantics	twitter soft moderation (flagging without deranking)	Tweets relating to 2020 U.S. presidential election	75/25 train/test 	(2.ii) learning to rank model	(3.i) Total number of hits (matching tweets) produced; Mean and median pairwise similarity score between the entries of the spanning subset; Mean and median similarity score between the entries in spanning subset and the claim; Mean and median similarity score between the query and the claim; Mean and median value of the TextRank scores [57] of the query terms; Mean and median score of the Term Frequency-Inverse Document Frequency scores [75] of the query terms.	2020 U.S. presidential election	flags 20 times more tweets than Twitter, with only 3.93% false positives and 18.81% false negatives	n/a	n/a	n/a	TRUE
292	2022	Kim et al.	Phishing URL Detection: A Network-based Approach Robust to Evasion	ACM CCS '22	websites	(W.i) URL semantics ('phishiness')	detecting deliberately evasive URLs	assumes that analysis of site URLs is a more lightweight process than analysis of page contents	80/20 train/test	(2.iv) 'belief propagation' algorithm on graph of URLs, IP addresses, name servers, and substrings	(3.i) URL semantics; (3.iv) hosting infrastructure	n/a	F-1 of 0.891	n/a	n/a	n/a	TRUE
293	2021	Jemielniak and Krempovych	An analysis of AstraZeneca COVID-19 vaccine misinformation and fear mongering on Twitter	Public Health	networks	(N.ii); (A.i) coordinated sharing of anti-vax rumors	analyzing media discourse about the AstraZeneca COVID-19 vaccine on Twitter	221,922 tweets containing #AstraZeneca from 1/1/21-3/22/21	undisclosed	(2.i) similarity of tweet corpora embeddings; (2.iv) co-occurrence analysis on user graphs	(3.iii) edges between accounts with matching tweet text corpora; (3.i) linked URLs in tweets	Astra Zeneca vaccine misinformation	ranked list of news sources with most misinfo posts	n/a	n/a	n/a	FALSE
294	2020	Giglietto et al. 	It takes a village to manipulate the media: coordinated link sharing behavior during 2018 and 2019 Italian elections	Information, Communication, and Society	networks	(N.ii) coordinated link sharing	Brexit referendum; 2016 U.S. presidential election	two datasets of online Italian political news stories shared on Facebook during the six months preceding the 2018 Italian general election (N = 84,815) and the 2019 European election (N = 164,760)	undisclosed	(2.iv) authors plot clustering coefficients of networks; don't use to classify new data	(3.iii) timestamps of URL sharing; (3.i) comparison of URLs to known blacklisted URLs	Italian political news	does not present classification results	n/a	n/a	n/a	FALSE
295	2016	Ferrara et al. 	The rise of social bots	Communications of the ACM	networks	(N.ii) coordinated accounts (bots)	n/a	[commentary]	n/a	humans and bots increasingly difficult to distinguish; 'the race will be over only when the effectiveness of early detection will sufficiently increase the cost of deception'	behaviors vs network patterns	n/a	n/a	n/a	n/a	n/a	FALSE
296_f	2020	Assenmacher, Clever, Pohl, Trautmann, Grimme	A Two-Phase Framework for Detecting Manipulation Campaigns in Social Media	Social Computing and Social Media	networks	(N.ii) campaigns	proposes human-in-the-loop for semi-automatic detection of campaigns; highlights difficulties of distinguishing organic and (malicious) coordinated campaigns	Twitter API queried in days preceding and following Brexit	none disclosed 	(2.iv) clustering on embedding similarity	(3.i) text stream processed into TF-IDF embedding vectors; clustered by similarity	Brexit	identifies cluster corresponding to known rumoring narratives	n/a	n/a	n/a	TRUE
297	2023	Ezzeddine et al. 	Exposing influence campaigns in the age of LLMs: a behavioral-based AI approach to detecting state-sponsored trolls	EPJ Data Science	networks	(N.ii) campaigns; Russian trolls	detection of Russian trolls in wake of 2016 U.S. presidential election	dataset of known Russian trolls involved in the interference of the 2016 U.S. Presidential election. 	10-fold x validation	(2.iii) LSTM-based classifier	(3.ii) 'our approach solely relies on the online behavior of accounts, specifically, the temporal sequence of online activities performed by a user'; we consider both the actions performed by an account, namely active online activities, and the feedback received by others, namely passive online activities, e.g., received replies and retweets. 	mixed topic	method identifies account sequences with an AUC close to 99% and accurately differentiates between Russian trolls and organic users with an AUC of 91%	n/a	n/a	n/a	TRUE
298_f	2021	Leonardi et al.	Automated Classification of Fake News Spreaders to Break the Misinformation Chain	Information	users	users might spread misinfo without malicious intent	(U.i) user stance from tweet embeddings	CoAID dataset; includes 4251 fact-checked news and 296,000 twitter user engagements with those articles	10-fold x validation	(2.iii) stacked NN	(3.i) word embeddings for tweet content; (3.ii) undisclosed user-level features derived from each account's posts	COVID	precision 0.8042, recall 0.8110, F1 0.8076	none described	none described	 https://github.com/D2KLab/stopfaker; compared to RF Fake News Spreader Classifier, Giachanou et al., and Mixed Fake News Spreader Classifie	FALSE
299_f	2020	Sansonetti et al. 	Unreliable Users Detection in Social Media: Deep Learning Techniques for Automatic Detection	IEEE Access	users	detection of users 	(U.i) user account metadata semantics	568,315 tweets referencing news indexed on PolitiFact; 62,367 distinct news referenced by tweets, comprising 34,429 fake news and 29,938 verified news; 4,022 user profiles comprising 2,013 users publishing mostly fake news and 2,008 user profiles publishing mostly real news.	80/20 train/test; 5-fold x validation	(2.iii) LSTM, CNN	(3.iii) username length, bio length, age (3.ii) followership stats; (3.i) sentiment of posts created	U.S. political news	accuracy above 91%	none described	none described	comparison to SVM, KNN	FALSE
300_f	2019	Santia et al. 	Detecting Social Bots on Facebook in an Information Veracity Context	ICWSM	users	spread of social bots on Facebook during fall of 2016	(U.ii) user commenting activity	BuzzFace, comprising over 1.6 million comments made by over 800,000users	50/50 train/test; 10-fold x validation	(2.ii) mean-centered classifier	(3.iii) average response time, comment length, number of comments, number of links	U.S. political news	80% precision, 64% recall, 72% F1 for user detection	none described	none described	comparison to SVM, NB	FALSE
301_f	2017	Chen et al. 	Unsupervised rumor detection based on users’ behaviors using neural networks	Pattern Recognition Letters	users	exploiting crowd wisdom to detect rumors	(C.i) comment punctuation and pronoun use; (U.ii) frequency of comment interactions	1,257 rumors and 2,325 non-rumors crawled from Sina Weibo	none described	(2.iii) autoencoder	(3.i) number of smileys, fp-pronouns, hashtags, etc. in Weibo; (3.ii) similar statistics for comments on original Weibo	Chinese news rumors	accuracy 92.49% and F1 measure of 89.16%	none described	none described	none described	FALSE