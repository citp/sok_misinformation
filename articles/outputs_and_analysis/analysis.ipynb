{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecff8657",
   "metadata": {},
   "source": [
    "### Suspicious writing/article detection\n",
    "\n",
    "This notebook contains code and documentation for reproducing results for the replication analysis of the paper \"Fake news detection: A hybrid CNN-RNN based deep learning approach.\" A link to the paper is available [here](https://www.researchgate.net/publication/348379370_Fake_news_detection_A_hybrid_CNN-RNN_based_deep_learning_approach).\n",
    "\n",
    "If you'd like to run all analyses from the original datasets--comprising 40K+ original and modified news articles and excerpts--start with \"__To run analysis from scratch__.\" If you'd like to skip classifier training and testing and calculate summary statistics only, jump to \"__To run analysis from provided files__.\"\n",
    "\n",
    "__To run analysis from scratch__:\n",
    "\n",
    "- Confirm that Python v3.10 (or later) and IPython v8 (or later) are installed. \n",
    "- On your own machine, move all data files (`real_nytimes.csv`, `modified_nytimes.csv`, `real_reuters.csv`, `modified_reuters.csv`, `isot.csv`, and `fakes.csv`) to the same directory as the bashscript `run.sh`. These data files will need to be downloaded from the zip archive at this [GDrive link](https://drive.google.com/file/d/1h8ML2LS8g44M2WpyX2L7Lr_bVMHECftL/view?usp=sharing). The `DataPrep` directory (from the zip archive) should also be in the same directory as the bashscript and all four csvs.  \n",
    "- Confirm also that pyscripts `CNN_revised.py` and `CNN_RNN.py` are in the same directory as all the above. Descriptions of both follow:    \n",
    "&nbsp;\n",
    "    - `CNN_RNN.py` is a lightly edited version of the original classifier provided by the authors. We added an argparser to make the script callable from `run.sh`; all model parameters are unchanged. \n",
    "    - `CNN_revised.py` ingests modified and original versions of our custom news datasets, preprocesses and pads them together (this is a necessary step, as the model accepts same-length inputs only), trains the classifier on the ISOT dataset, then tests on original and modified news datasets.    \n",
    "&nbsp;\n",
    "- At the conclusion of this run (wall time approximately 7.5 hours on 4 threads; see `run.sh` for more info), you'll have generated four files containing console logs and classification reports for 30 seeded runs on each dataset: `final_metrics_isot.txt`, `final_metrics_fakes.txt`, `final_metrics_reu.txt`, and `final_metrics_nyt.txt`. Note: The modified and original (real) classification reports for each of the Reuters and NYTimes datasets are bundled into the same datafile. So `final_metrics_nyt.txt` will contain classification reports for runs on the real and modified NYTimes datasets. These reports contain accuracy, FPR, FNR, and other performance measurements. \n",
    "- You'll also optionally generate the label files for all modified datasets. These are named `y_bin_pred_original_{nyt/reu}_{randseed}.csv`. There are 60 of these: one for each combination of nyt/reu and every seed in our list of 30 random seeds. \n",
    "- To complete analysis on output files, continue with instructions in the next section. \n",
    "\n",
    "\n",
    "__To run analysis from provided files__:\n",
    "\n",
    "- Confirm that `final_metrics_isot.txt`, `final_metrics_fakes.txt`, `final_metrics_reu.txt`, and `final_metrics_nyt.txt` are available in the same directory as this notebook. \n",
    "- Run cells in order.* Note that classification reports for both modified news datasets in the `final_metrics_` data files are over the whole set of 100 excerpts, including those 50 excerpts that appear in original, unmodified form between `real` and `modified` versions of both news datasets. \n",
    "- In our paper, we report accuracy and FNRs over the set of 50 modified excerpts only. To calculate these statistics, see Section \"Modified Dataset Statistics.\" These require the label prediction files `y_bin_pred_original_{nyt/reu}_{randseed}.csv` mentioned previously. These files contain the label (true/false) predictions output by the trained model. If you skipped the previous section, sample label files are provided in the `outputs_and_analysis` directory. __Note__: yes, it'd definitely be easier to compute these stats in the pyscripts themselves and output directly to console or a self-contained datafile. These updates are in-progress; doing things the klugey way just for now. \n",
    "\n",
    "*For the sake of explainability and transparency, we err on the side of verbosity in this notebook: though in-order execution is recommended, we repeat the same function calls for each unique dataset such that each analysis cell can be run independently and out of order without affecting results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eccbbe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f071bd2",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "__(1) ISOT dataset analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03afb99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(mean, var) : (1.00, 0.00)\n",
      "fnr(mean, var) : (0.34, 0.22)\n",
      "fpr(mean, var) : (0.33, 0.22)\n"
     ]
    }
   ],
   "source": [
    "# ISOT analysis: training on 0.8 ISOT, validating/testing on 0.2 ISOT\n",
    "\n",
    "# pull acc, FPR, FNR from ISOT output files\n",
    "with open(\"final_metrics_isot.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "seed = re.findall(r'RANDOM SEED:\\s*(\\d+)', text)\n",
    "accuracy_matches = re.findall(r'accuracy\\s+([\\d.]+)', text)\n",
    "fpr_matches = re.findall(r'FPR:\\s+\\[([^\\]]+)\\]', text)\n",
    "fnr_matches = re.findall(r'FNR:\\s+\\[([^\\]]+)\\]', text)\n",
    "\n",
    "parsed = []\n",
    "for seed, acc, fpr_str, fnr_str in zip(seed, accuracy_matches, fpr_matches, fnr_matches):\n",
    "    seed = int(seed)\n",
    "    acc = float(acc)\n",
    "    fpr = [float(x) for x in fpr_str.strip().split()]\n",
    "    fnr = [float(x) for x in fnr_str.strip().split()]\n",
    "    parsed.append((seed, acc, fpr, fnr))\n",
    "\n",
    "print(f\"acc(mean, var) : ({np.mean(acc):.2f}, {np.var(acc):.2f})\")\n",
    "print(f\"fnr(mean, var) : ({np.mean(fpr):.2f}, {np.var(fpr):.2f})\")\n",
    "print(f\"fpr(mean, var) : ({np.mean(fnr):.2f}, {np.var(fnr):.2f})\")\n",
    "\n",
    "## optional: uncomment lines below to output extracted stats to tsv    \n",
    "# with open(\"final_extracted_metrics_fakes.tsv\", \"w\") as out:\n",
    "#     out.write(\"Run\\tSeed\\tAccuracy\\tFPR_1\\tFNR_1\\n\")\n",
    "#     for i, (seed, acc, fpr, fnr) in enumerate(parsed, 1):\n",
    "#         out.write(f\"{i}\\t{seed}\\t{acc:.4f}\\t{fpr[1]:.6f}\\t{fnr[1]:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1db92c",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "__(2) FAKES dataset analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1c3d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(mean, var) : (0.58, 0.00)\n",
      "fnr(mean, var) : (0.50, 0.25)\n",
      "fpr(mean, var) : (0.50, 0.25)\n"
     ]
    }
   ],
   "source": [
    "## FAKES analysis: training on ISOT, testing on FAKES\n",
    "\n",
    "## pull acc, FPR, FNR from FAKES output files\n",
    "\n",
    "with open(\"final_metrics_fakes.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "seed = re.findall(r'RANDOM SEED:\\s*(\\d+)', text)\n",
    "accuracy_matches = re.findall(r'accuracy\\s+([\\d.]+)', text)\n",
    "fpr_matches = re.findall(r'FPR:\\s+\\[([^\\]]+)\\]', text)\n",
    "fnr_matches = re.findall(r'FNR:\\s+\\[([^\\]]+)\\]', text)\n",
    "\n",
    "parsed = []\n",
    "for seed, acc, fpr_str, fnr_str in zip(seed, accuracy_matches, fpr_matches, fnr_matches):\n",
    "    seed = int(seed)\n",
    "    acc = float(acc)\n",
    "    fpr = [float(x) for x in fpr_str.strip().split()]\n",
    "    fnr = [float(x) for x in fnr_str.strip().split()]\n",
    "    parsed.append((seed, acc, fpr, fnr))\n",
    "\n",
    "print(f\"acc(mean, var) : ({np.mean(acc):.2f}, {np.var(acc):.2f})\")\n",
    "print(f\"fnr(mean, var) : ({np.mean(fpr):.2f}, {np.var(fpr):.2f})\")\n",
    "print(f\"fpr(mean, var) : ({np.mean(fnr):.2f}, {np.var(fnr):.2f})\")\n",
    "\n",
    "## optional: output extracted stats to tsv \n",
    "# with open(\"final_extracted_metrics_isot.tsv\", \"w\") as out:\n",
    "#     out.write(\"Run\\tSeed\\tAccuracy\\tFPR_1\\tFNR_1\\n\")\n",
    "#     for i, (seed, acc, fpr, fnr) in enumerate(parsed, 1):\n",
    "#         out.write(f\"{i}\\t{seed}\\t{acc:.4f}\\t{fpr[1]:.6f}\\t{fnr[1]:.6f}\\n\")\n",
    "#         out.write(\"\\t\".join(str(item) for item in row) + \"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23ce69",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "__(3) Reuters original and modified dataset analyis__\n",
    "\n",
    "Note: modified dataset statistics are reported over the whole set of 100 excerpts, including those 50 excerpts that are unchanged between original and modified datasets. For statistics over the set of modified articles only, see the next section (3.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6236d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics on both Reuters datasets (modified statistics are over the full dataset of 100 excerpts):\n",
      "orig acc(mean, var) : (0.60, 0.02)\n",
      "orig FNR(mean, var) : (0.40, 0.02)\n",
      "modif acc(mean, var) : (0.57, 0.00)\n"
     ]
    }
   ],
   "source": [
    "# generate separate extraction files for original and unmodified Reuters datasets\n",
    "\n",
    "input_file = \"final_metrics_reu.txt\"\n",
    "orig_output_file = \"orig_results_reu.tsv\"\n",
    "mod_output_file = \"mod_results_reu.tsv\"\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "reu_orig_results = []\n",
    "reu_mod_results = []\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i]\n",
    "\n",
    "    # fetch random seed \n",
    "    if \"RANDOM SEED:\" in line:\n",
    "        seed_match = re.search(r'RANDOM SEED:\\s*(\\d+)', line)\n",
    "        seed = seed_match.group(1) if seed_match else \"NA\"\n",
    "\n",
    "    # orig block\n",
    "    if \"Original Classification Report:\" in line:\n",
    "        while i < len(lines) and \"accuracy\" not in lines[i]:\n",
    "            i += 1\n",
    "        if i < len(lines):\n",
    "            acc_match = re.search(r'accuracy\\s+(\\d+\\.\\d+)', lines[i])\n",
    "            orig_acc = acc_match.group(1) if acc_match else \"NA\"\n",
    "            reu_orig_results.append([int(seed), float(orig_acc), 1 - float(orig_acc)])\n",
    "\n",
    "    # modif block\n",
    "    if \"Modified Classification Report:\" in line:\n",
    "        while i < len(lines) and \"accuracy\" not in lines[i]:\n",
    "            i += 1\n",
    "        if i < len(lines):\n",
    "            acc_match = re.search(r'accuracy\\s+(\\d+\\.\\d+)', lines[i])\n",
    "            mod_acc = acc_match.group(1) if acc_match else \"NA\"\n",
    "        fpr, fnr = \"NA\", \"NA\"\n",
    "        while i < len(lines):\n",
    "            if \"FPR:\" in lines[i]:\n",
    "                fpr_line = lines[i]\n",
    "                fpr_match = re.search(r'FPR:\\s+\\[([^\\]]+)\\]', fpr_line)\n",
    "                if fpr_match:\n",
    "                    fpr_vals = [float(v.strip()) for v in fpr_match.group(1).split()]\n",
    "                    fpr = f\"{fpr_vals[1]:.4f}\" if len(fpr_vals) > 1 else \"NA\"\n",
    "            if \"FNR:\" in lines[i]:\n",
    "                fnr_line = lines[i]\n",
    "                fnr_match = re.search(r'FNR:\\s+\\[([^\\]]+)\\]', fnr_line)\n",
    "                if fnr_match:\n",
    "                    fnr_vals = [float(v.strip()) for v in fnr_match.group(1).split()]\n",
    "                    fnr = f\"{fnr_vals[1]:.4f}\" if len(fnr_vals) > 1 else \"NA\"\n",
    "                reu_mod_results.append([int(seed), float(mod_acc), float(fpr), float(fnr)])\n",
    "                break\n",
    "            i += 1\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# # optional: write original results\n",
    "# with open(orig_output_file, 'w') as f:\n",
    "#     f.write(\"seed\\taccuracy\\n\")\n",
    "#     for row in orig_results:\n",
    "#         # f.write(\"\\t\".join(row) + \"\\n\")\n",
    "#         f.write(\"\\t\".join(str(item) for item in row) + \"\\n\")\n",
    "\n",
    "# # optional: write modified results\n",
    "# with open(mod_output_file, 'w') as f:\n",
    "#     f.write(\"seed\\taccuracy\\tFPR\\tFNR\\n\")\n",
    "#     for row in reu_mod_results:\n",
    "#         f.write(\"\\t\".join(str(item) for item in row) + \"\\n\")\n",
    "        \n",
    "reu_orig_df = pd.DataFrame(reu_orig_results, columns = ['seed', 'accuracy', 'FNR'])\n",
    "reu_modif_df = pd.DataFrame(reu_mod_results, columns = ['seed', 'accuracy', 'FPR', 'FNR'])\n",
    "\n",
    "print(\"Summary statistics on both Reuters datasets (modified statistics are over the full dataset of 100 excerpts):\")\n",
    "print(f\"orig acc(mean, var) : ({np.mean(reu_orig_df['accuracy']):.2f}, {np.var(reu_orig_df['accuracy']):.2f})\")\n",
    "print(f\"orig FNR(mean, var) : ({np.mean(reu_orig_df['FNR']):.2f}, {np.var(reu_orig_df['FNR']):.2f})\")\n",
    "print(f\"modif acc(mean, var) : ({np.mean(reu_modif_df['accuracy']):.2f}, {np.var(reu_modif_df['accuracy']):.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b3c2e",
   "metadata": {},
   "source": [
    "__(3.5) Reuters modified dataset analysis__\n",
    "\n",
    "... by contrast with the modified dataset analysis in the previous cell, these statistics are over the set of _edited_ Reuters articles (n = 50) only. The accuracy statistics (mean and variance) should be self-explanatory; the `flips` statistic measures the average number of toggled labels (i.e., from 0 -> 1 or 1 -> 0) between the original and modified datasets for the 50 edited excerpts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0f82af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "reu_mod var(acc):  0.02203555555555555\n",
      "reu mod mean(acc):  0.4733333333333334\n",
      "reu flips average:  1.1\n"
     ]
    }
   ],
   "source": [
    "seeds=[384, 328, 479, 21, 304, 355, 285, 105, 135,\n",
    "       263, 91, 88, 73, 177, 7, 66, 492, 344, 402,\n",
    "       274, 467, 413, 339, 427, 201, 373, 214, 223, 366, 246]\n",
    "\n",
    "reu_mod_acc = []\n",
    "\n",
    "reu_flips = [0]*30\n",
    "\n",
    "for j in range(len(seeds)):\n",
    "\n",
    "    reu_orig = pd.read_csv(f'y_bin_pred_original_reuters_{seeds[j]}.csv')\n",
    "    reu_orig = np.array(reu_orig)\n",
    "    \n",
    "    reu_modif = pd.read_csv(f'y_bin_pred_modified_reuters_{seeds[j]}.csv')\n",
    "    reu_modif = np.array(reu_modif)\n",
    "    \n",
    "    reu_mod = (50 - reu_modif[0:50].sum()) / 50 \n",
    "    reu_mod_acc.append(reu_mod)  \n",
    "    \n",
    "    for i in range(50):\n",
    "        \n",
    "        if reu_orig[i] != reu_modif[i]:\n",
    "            reu_flips[j] += 1\n",
    "    \n",
    "#     print('------------')\n",
    "#     print('seed: ', seeds[j])\n",
    "#     print('reu mod acc: ', np.sum(reu_mod))\n",
    "    \n",
    "    \n",
    "print('----------')\n",
    "print('reu_mod var(acc): ', np.var(reu_mod_acc))\n",
    "print('reu mod mean(acc): ', np.mean(reu_mod_acc))\n",
    "print('reu flips average: ', np.mean(reu_flips))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3516a",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "__(4) NYTimes original and modified dataset analyis__\n",
    "\n",
    "Note: modified dataset statistics are reported over the whole set of 100 excerpts, including those 50 excerpts that are unchanged between original and modified datasets. For statistics over the set of modified articles only, see the next section (4.5). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cb9288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics on both NYTimes datasets (modified dataset statistics are over the full dataset of 100 excerpts):\n",
      "orig acc(mean, var) : (0.49, 0.03)\n",
      "orig FNR(mean, var) : (0.51, 0.03)\n",
      "modif acc(mean, var) : (0.49, 0.00)\n"
     ]
    }
   ],
   "source": [
    "# generate separate extraction files for original and unmodified NYTimes datasets\n",
    "\n",
    "input_file = \"final_metrics_nyt.txt\"\n",
    "orig_output_file = \"orig_results_nyt.tsv\"\n",
    "mod_output_file = \"mod_results_nyt.tsv\"\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "nyt_orig_results = []\n",
    "nyt_mod_results = []\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i]\n",
    "\n",
    "    # fetch random seed \n",
    "    if \"RANDOM SEED:\" in line:\n",
    "        seed_match = re.search(r'RANDOM SEED:\\s*(\\d+)', line)\n",
    "        seed = seed_match.group(1) if seed_match else \"NA\"\n",
    "\n",
    "    # orig block\n",
    "    if \"Original Classification Report:\" in line:\n",
    "        while i < len(lines) and \"accuracy\" not in lines[i]:\n",
    "            i += 1\n",
    "        if i < len(lines):\n",
    "            acc_match = re.search(r'accuracy\\s+(\\d+\\.\\d+)', lines[i])\n",
    "            orig_acc = acc_match.group(1) if acc_match else \"NA\"\n",
    "            nyt_orig_results.append([int(seed), float(orig_acc), 1 - float(orig_acc)])\n",
    "\n",
    "    # modif block\n",
    "    if \"Modified Classification Report:\" in line:\n",
    "        while i < len(lines) and \"accuracy\" not in lines[i]:\n",
    "            i += 1\n",
    "        if i < len(lines):\n",
    "            acc_match = re.search(r'accuracy\\s+(\\d+\\.\\d+)', lines[i])\n",
    "            mod_acc = acc_match.group(1) if acc_match else \"NA\"\n",
    "        fpr, fnr = \"NA\", \"NA\"\n",
    "        while i < len(lines):\n",
    "            if \"FPR:\" in lines[i]:\n",
    "                fpr_line = lines[i]\n",
    "                fpr_match = re.search(r'FPR:\\s+\\[([^\\]]+)\\]', fpr_line)\n",
    "                if fpr_match:\n",
    "                    fpr_vals = [float(v.strip()) for v in fpr_match.group(1).split()]\n",
    "                    fpr = f\"{fpr_vals[1]:.4f}\" if len(fpr_vals) > 1 else \"NA\"\n",
    "            if \"FNR:\" in lines[i]:\n",
    "                fnr_line = lines[i]\n",
    "                fnr_match = re.search(r'FNR:\\s+\\[([^\\]]+)\\]', fnr_line)\n",
    "                if fnr_match:\n",
    "                    fnr_vals = [float(v.strip()) for v in fnr_match.group(1).split()]\n",
    "                    fnr = f\"{fnr_vals[1]:.4f}\" if len(fnr_vals) > 1 else \"NA\"\n",
    "                nyt_mod_results.append([int(seed), float(mod_acc), float(fpr), float(fnr)])\n",
    "                break\n",
    "            i += 1\n",
    "    i += 1\n",
    "\n",
    "# # optional: write original results\n",
    "# with open(orig_output_file, 'w') as f:\n",
    "#     f.write(\"seed\\taccuracy\\n\")\n",
    "#     for row in orig_results:\n",
    "#         f.write(\"\\t\".join(row) + \"\\n\")\n",
    "\n",
    "# # optional: write modified results\n",
    "# with open(mod_output_file, 'w') as f:\n",
    "#     f.write(\"seed\\taccuracy\\tFPR\\tFNR\\n\")\n",
    "#     for row in mod_results:\n",
    "#         f.write(\"\\t\".join(row) + \"\\n\")\n",
    "\n",
    "nyt_orig_df = pd.DataFrame(nyt_orig_results, columns = ['seed', 'accuracy', 'FNR'])\n",
    "nyt_modif_df = pd.DataFrame(nyt_mod_results, columns = ['seed', 'accuracy', 'FPR', 'FNR'])\n",
    "\n",
    "print(\"Summary statistics on both NYTimes datasets (modified dataset statistics are over the full dataset of 100 excerpts):\")\n",
    "print(f\"orig acc(mean, var) : ({np.mean(nyt_orig_df['accuracy']):.2f}, {np.var(nyt_orig_df['accuracy']):.2f})\")\n",
    "print(f\"orig FNR(mean, var) : ({np.mean(nyt_orig_df['FNR']):.2f}, {np.var(nyt_orig_df['FNR']):.2f})\")\n",
    "print(f\"modif acc(mean, var) : ({np.mean(nyt_modif_df['accuracy']):.2f}, {np.var(nyt_modif_df['accuracy']):.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd21930",
   "metadata": {},
   "source": [
    "__(4.5) NYTimes modified dataset analysis__\n",
    "\n",
    "... by contrast with the modified dataset analysis in the previous cell, these statistics are over the set of _edited_ NYT articles (n = 50) only. The accuracy statistics (mean and variance) should be self-explanatory; the `flips` statistic measures the average number of toggled labels (i.e., from 0 -> 1 or 1 -> 0) between the original and modified datasets for the 50 edited excerpts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12d6f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "nyt mod variance:  0.04125333333333333\n",
      "nyt mod average:  0.52\n",
      "nyt flips average:  1.4333333333333333\n"
     ]
    }
   ],
   "source": [
    "seeds=[384, 328, 479, 21, 304, 355, 285, 105, 135,\n",
    "       263, 91, 88, 73, 177, 7, 66, 492, 344, 402,\n",
    "       274, 467, 413, 339, 427, 201, 373, 214, 223, 366, 246]\n",
    "\n",
    "nyt_mod_acc = []\n",
    "\n",
    "nyt_flips = [0]*30\n",
    "\n",
    "\n",
    "for j in range(len(seeds)):\n",
    "\n",
    "    nyt_orig = pd.read_csv(f'y_bin_pred_original_nytimes_{seeds[j]}.csv') \n",
    "    nyt_orig = np.array(nyt_orig)\n",
    "    \n",
    "    nyt_modif = pd.read_csv(f'y_bin_pred_modified_nytimes_{seeds[j]}.csv')\n",
    "    nyt_modif = np.array(nyt_modif)\n",
    "    \n",
    "    nyt_mod = (50 - nyt_modif[0:50].sum()) / 50\n",
    "    nyt_mod_acc.append(nyt_mod)\n",
    "    \n",
    "    for i in range(50):\n",
    "        \n",
    "        if nyt_orig[i] != nyt_modif[i]:\n",
    "            nyt_flips[j] += 1\n",
    "        \n",
    "#   # print per-run statistics:   \n",
    "#     print('seed: ', seeds[j])\n",
    "#     print('nyt mod acc: ', np.sum(nyt_mod))\n",
    "#     print('------------')\n",
    "    \n",
    "print('----------')\n",
    "print('nyt mod variance: ', np.var(nyt_mod_acc))\n",
    "print('nyt mod average: ', np.mean(nyt_mod_acc))\n",
    "print('nyt flips average: ', np.mean(nyt_flips))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631501e",
   "metadata": {},
   "source": [
    "__(5) Pairwise significance test__ \n",
    "\n",
    "For significance testing of model performance on original NYTimes versus original Reuters datasets. This analysis requires that you run the analysis in sections (3) and (4) first in order to initialize `nyt_orig_df` and `reu_orig_df.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67a6797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.000374963616536027\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t_stat, p_val = ttest_ind(nyt_orig_df['accuracy'], reu_orig_df['accuracy'])\n",
    "print(f\"p = {p_val}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
